import json
import numpy as np
import os
import glob
import tiktoken
import csv
import argparse
import sys

# åˆå§‹åŒ–tokenizer
def get_tokenizer(model_name="gpt-4o"):
    """è·å–tokenizer"""
    try:
        return tiktoken.encoding_for_model(model_name)
    except:
        return tiktoken.get_encoding("cl100k_base")

def count_tokens_tiktoken(text, tokenizer):
    """ä½¿ç”¨tiktokenè®¡ç®—tokenæ•°"""
    if isinstance(text, str):
        try:
            return len(tokenizer.encode(text, disallowed_special=()))
        except Exception as e:
            print(f"Warning: tiktoken encoding failed: {e}")
            return len(text.split())
    return 0

def count_tokens_simple(text):
    """ç®€å•çš„tokenè®¡ç®—æ–¹æ³•ï¼ˆæŒ‰ç©ºæ ¼åˆ†è¯ï¼‰"""
    if isinstance(text, str):
        return len(text.split())
    return 0

def count_characters(text):
    """è®¡ç®—å­—ç¬¦æ•°"""
    if isinstance(text, str):
        return len(text)
    return 0

def load_summary_file(base_dir):
    """åŠ è½½summaryæ–‡ä»¶ï¼Œè·å–åˆ†ç»„ä¿¡æ¯"""
    # æŸ¥æ‰¾summaryæ–‡ä»¶
    summary_files = glob.glob(os.path.join(base_dir, "summary-*.json"))
    
    if not summary_files:
        return None
    
    # ä½¿ç”¨æœ€æ–°çš„summaryæ–‡ä»¶
    summary_file = max(summary_files, key=os.path.getmtime)
    
    try:
        with open(summary_file, 'r') as f:
            summary_data = json.load(f)
        
        print(f"âœ… æ‰¾åˆ°summaryæ–‡ä»¶: {os.path.basename(summary_file)}")
        
        # æ£€æŸ¥æ˜¯å¦å¯ç”¨äº†åˆ†ç»„
        group_by_seed = summary_data.get('group_by_seed', False)
        config_groups = summary_data.get('config_groups', None)
        
        if group_by_seed and config_groups:
            print(f"âœ… æ£€æµ‹åˆ°é…ç½®åˆ†ç»„ï¼ˆgroup_by_seed=Trueï¼‰")
            print(f"   å…± {len(config_groups)} ä¸ªé…ç½®ç»„")
            return {
                'group_by_seed': True,
                'config_groups': {int(k): v for k, v in config_groups.items()},
                'summary_data': summary_data
            }
        else:
            print(f"   æœªå¯ç”¨é…ç½®åˆ†ç»„ï¼ˆgroup_by_seed=False æˆ–æ— åˆ†ç»„ä¿¡æ¯ï¼‰")
            return {
                'group_by_seed': False,
                'config_groups': None,
                'summary_data': summary_data
            }
    except Exception as e:
        print(f"âš ï¸  è¯»å–summaryæ–‡ä»¶å¤±è´¥: {e}")
        return None

def extract_text_from_content(content):
    """ä»Claude Agent SDKçš„contentæ ¼å¼ä¸­æå–æ–‡æœ¬"""
    if isinstance(content, str):
        return content
    elif isinstance(content, list):
        text_parts = []
        for item in content:
            if isinstance(item, dict):
                if item.get("type") == "TextBlock":
                    text_parts.append(item.get("text", ""))
                elif item.get("type") == "text":
                    # ToolResultBlockå†…éƒ¨çš„textæ ¼å¼: {"type": "text", "text": "..."}
                    text_parts.append(item.get("text", ""))
                elif item.get("type") == "ToolUseBlock":
                    # å°†tool useè½¬æ¢ä¸ºJSONå­—ç¬¦ä¸²æ¥è®¡ç®—tokens
                    try:
                        text_parts.append(json.dumps(item, ensure_ascii=False))
                    except:
                        pass
                elif item.get("type") == "ToolResultBlock":
                    # Tool resultçš„å†…å®¹
                    result_content = item.get("content", "")
                    if isinstance(result_content, str):
                        text_parts.append(result_content)
                    elif isinstance(result_content, list):
                        # é€’å½’å¤„ç†åµŒå¥—çš„content
                        text_parts.append(extract_text_from_content(result_content))
            elif isinstance(item, str):
                text_parts.append(item)
        return "\n".join(text_parts)
    return ""

def analyze_config_file(json_path, tokenizer):
    """åˆ†æå•ä¸ªconfigæ–‡ä»¶ï¼ˆå•æ¬¡runï¼‰"""
    try:
        with open(json_path, "r") as f:
            data = json.load(f)

        stats = {
            'total_messages': 0,
            'tool_calls': 0,
            'user_messages': 0,
            'assistant_messages': 0,
            'tool_content_chars': 0,
            'tool_content_words': 0,
            'tool_content_tokens': 0,
            'all_content_chars': 0,
            'all_content_words': 0,
            'all_content_tokens': 0,
            'tool_content_list': [],
            'api_total_tokens': 0,  # APIè°ƒç”¨çš„æ€»tokens
            'api_prompt_tokens': 0,
            'api_completion_tokens': 0,
            'api_total_cost': 0.0,  # APIè°ƒç”¨çš„æ€»cost
            'accuracy': 0.0,  # å‡†ç¡®åº¦
            'total_steps': 0,  # æ€»æ­¥æ•°
            'completed': False,  # æ˜¯å¦å®Œæˆ
            'has_context_length_error': False,  # æ˜¯å¦å‡ºç°context length error
            'proper_ending': False,  # æ˜¯å¦æ­£å¸¸ç»“æŸï¼ˆaccuracy=1.0 æˆ– æœ€åçš„assistant messageåŒ…å«claim_done_claim_doneï¼‰
            'reset_count': 0,  # resetäº‹ä»¶æ¬¡æ•°
            'summary_count': 0,  # summaryäº‹ä»¶æ¬¡æ•°
            'trim_count': 0,  # trimäº‹ä»¶æ¬¡æ•°
            'thinking_reset_count': 0,  # thinking_resetäº‹ä»¶æ¬¡æ•°
            'tokens_before_each_assistant': [],  # è®°å½•æ¯æ¬¡assistantå›å¤å‰çš„ç´¯è®¡tokens
            'trimmed_tokens_total': 0,  # è¢«trimæ‰çš„tokensæ€»æ•°
            'reset_tokens_total': 0,  # è¢«resetæ‰çš„tokensæ€»æ•°
            'thinking_reset_tokens_total': 0,  # è¢«thinking_resetæ‰çš„tokensæ€»æ•°
            'summary_tokens_total': 0,  # è¢«summaryæ‰çš„tokensæ€»æ•°
            'has_error': False,  # æ˜¯å¦åŒ…å«errorç±»å‹çš„actionï¼ˆç”¨äºæ’é™¤tokenç»Ÿè®¡ï¼‰
        }
        
        # æ£€æŸ¥stepsä¸­æ˜¯å¦æœ‰errorç±»å‹çš„action
        if "steps" in data:
            for step in data["steps"]:
                if "action" in step and isinstance(step["action"], dict):
                    if step["action"].get("type") == "error":
                        stats['has_error'] = True
                        break

        # æå–accuracy, total_steps, completed
        # ä½¿ç”¨ or ç¡®ä¿ None å€¼è¢«è½¬æ¢ä¸ºé»˜è®¤å€¼
        stats['accuracy'] = data.get('accuracy', 0.0) or 0.0
        stats['total_steps'] = data.get('total_steps', 0) or 0
        stats['completed'] = data.get('completed', False) or False

        # ç»Ÿè®¡resetã€summaryã€trimå’Œthinking_resetäº‹ä»¶æ¬¡æ•°ï¼ˆå…¼å®¹ä¸‰ç§æ ¼å¼ï¼‰
        # 1. æ—§æ ¼å¼ï¼šreset_events, summary_eventsç­‰
        stats['reset_count'] = len(data.get('reset_events', []))
        stats['summary_count'] = len(data.get('summary_events', []))
        stats['trim_count'] = len(data.get('trim_events', []))
        stats['thinking_reset_count'] = len(data.get('thinking_reset_events', []))

        # è®¡ç®—è¢«trimæ‰çš„tokensæ€»æ•°
        trim_events = data.get('trim_events', [])
        for trim_event in trim_events:
            trim_info = trim_event.get('trim_info', {})
            original_tokens = trim_info.get('original_total_tokens', 0)
            trimmed_tokens = trim_info.get('trimmed_total_tokens', 0)
            stats['trimmed_tokens_total'] += (original_tokens - trimmed_tokens)

        # è®¡ç®—è¢«resetæ‰çš„tokensæ€»æ•°
        reset_events = data.get('reset_events', [])
        
        # æ„å»ºstepåˆ°usageçš„æ˜ å°„ï¼Œç”¨äºæœ€ç²¾å‡†çš„ä¼°ç®—
        step_usage_map = {}
        if "steps" in data:
            for step in data["steps"]:
                step_info = step.get("info", {})
                tool_use_counter = step_info.get("tool_use_counter", 0)
                if tool_use_counter > 0:
                    usage = step.get("action", {}).get("raw_response", {}).get("usage", {})
                    step_usage_map[tool_use_counter] = usage
        
        for reset_event in reset_events:
            tokens_before = reset_event.get('tokens_before_reset', 0)
            tokens_after = reset_event.get('tokens_after_reset', 0)
            # å…¼å®¹æ—§æ ¼å¼ï¼šå¦‚æœæ²¡æœ‰tokens_before_resetï¼Œå°è¯•ä½¿ç”¨total_tokens
            if tokens_before == 0:
                tokens_before = reset_event.get('total_tokens', 0)
            
            # å¦‚æœæ²¡æœ‰tokens_after_resetï¼Œå°è¯•ä¼°ç®—
            if tokens_after == 0 and tokens_before > 0:
                # æœ€ç²¾å‡†æ–¹æ³•: ä½¿ç”¨resetåä¸‹ä¸€æ­¥çš„prompt_tokens
                reset_step = reset_event.get('step', 0)
                next_step_num = reset_step + 1
                if next_step_num in step_usage_map:
                    next_usage = step_usage_map[next_step_num]
                    tokens_after = next_usage.get('prompt_tokens', 0)
                
                # å¦‚æœæœ€ç²¾å‡†æ–¹æ³•å¤±è´¥ï¼Œä½¿ç”¨æ¶ˆæ¯æ•°é‡æ¯”ä¾‹ä¼°ç®—
                if tokens_after == 0:
                    messages_before = reset_event.get('messages_before_count', 0)
                    messages_after = reset_event.get('messages_after_count', 0)
                    if messages_before > 0 and messages_after > 0:
                        tokens_after = int(tokens_before * (messages_after / messages_before))
                    else:
                        # å¤‡é€‰: åŸºäºç§»é™¤çš„æ¶ˆæ¯å¯¹æ¯”ä¾‹ä¼°ç®—
                        reset_info = reset_event.get('reset_info', {})
                        num_pairs_removed = reset_info.get('num_pairs_removed', 0)
                        total_pairs = reset_info.get('total_pairs', 0)
                        if total_pairs > 0 and num_pairs_removed > 0:
                            tokens_after = int(tokens_before * (1 - num_pairs_removed / total_pairs))
            
            if tokens_before and tokens_after:
                stats['reset_tokens_total'] += (tokens_before - tokens_after)

        # è®¡ç®—è¢«thinking_resetæ‰çš„tokensæ€»æ•°
        thinking_reset_events = data.get('thinking_reset_events', [])
        for thinking_reset_event in thinking_reset_events:
            tokens_before = thinking_reset_event.get('tokens_before_reset', 0)
            tokens_after = thinking_reset_event.get('tokens_after_reset', 0)
            # å…¼å®¹æ—§æ ¼å¼ï¼šå¦‚æœæ²¡æœ‰tokens_before_resetï¼Œå°è¯•ä½¿ç”¨total_tokens
            if tokens_before == 0:
                tokens_before = thinking_reset_event.get('total_tokens', 0)
            
            # å¦‚æœæ²¡æœ‰tokens_after_resetï¼Œå°è¯•ä¼°ç®—
            if tokens_after == 0 and tokens_before > 0:
                # æœ€ç²¾å‡†æ–¹æ³•: ä½¿ç”¨thinking_resetåä¸‹ä¸€æ­¥çš„prompt_tokens
                reset_step = thinking_reset_event.get('step', 0)
                next_step_num = reset_step + 1
                if next_step_num in step_usage_map:
                    next_usage = step_usage_map[next_step_num]
                    tokens_after = next_usage.get('prompt_tokens', 0)
                
                # å¦‚æœæœ€ç²¾å‡†æ–¹æ³•å¤±è´¥ï¼Œä½¿ç”¨thinking_reset_infoä¼°ç®—
                if tokens_after == 0:
                    thinking_reset_info = thinking_reset_event.get('thinking_reset_info', {})
                    total_reasoning_length = thinking_reset_info.get('total_reasoning_content_length', 0)
                    # ç²—ç•¥ä¼°ç®—: 1 char â‰ˆ 0.25 tokens (è‹±æ–‡)
                    if total_reasoning_length > 0:
                        estimated_reasoning_tokens = int(total_reasoning_length * 0.25)
                        tokens_after = tokens_before - estimated_reasoning_tokens
            
            if tokens_before and tokens_after:
                stats['thinking_reset_tokens_total'] += (tokens_before - tokens_after)

        # è®¡ç®—è¢«summaryæ‰çš„tokensæ€»æ•°
        summary_events = data.get('summary_events', [])
        for summary_event in summary_events:
            tokens_before = summary_event.get('tokens_before_summary', 0)
            tokens_after = summary_event.get('tokens_after_summary', 0)
            # å…¼å®¹æ—§æ ¼å¼ï¼šå¦‚æœæ²¡æœ‰tokens_before_summaryï¼Œå°è¯•ä½¿ç”¨total_tokens
            if tokens_before == 0:
                tokens_before = summary_event.get('total_tokens', 0)
            
            # å¦‚æœæ²¡æœ‰tokens_after_summaryï¼Œå°è¯•ä¼°ç®—
            if tokens_after == 0 and tokens_before > 0:
                # æœ€ç²¾å‡†æ–¹æ³•: ä½¿ç”¨summaryåä¸‹ä¸€æ­¥çš„prompt_tokens
                summary_step = summary_event.get('step', 0)
                next_step_num = summary_step + 1
                if next_step_num in step_usage_map:
                    next_usage = step_usage_map[next_step_num]
                    tokens_after = next_usage.get('prompt_tokens', 0)
                
                # å¦‚æœæœ€ç²¾å‡†æ–¹æ³•å¤±è´¥ï¼Œä½¿ç”¨æ¶ˆæ¯æ•°é‡æ¯”ä¾‹ä¼°ç®—
                if tokens_after == 0:
                    messages_before = summary_event.get('messages_before_count', 0)
                    messages_after = summary_event.get('messages_after_count', 0)
                    if messages_before > 0 and messages_after > 0:
                        tokens_after = int(tokens_before * (messages_after / messages_before))
            
            if tokens_before and tokens_after:
                stats['summary_tokens_total'] += (tokens_before - tokens_after)

        # 2. Claude Agent SDKæ ¼å¼ï¼šclear_tool_results_eventså’Œcompact_events
        stats['reset_count'] += len(data.get('clear_tool_results_events', []))
        stats['summary_count'] += len(data.get('compact_events', []))

        # 3. run_claude_api.pyæ ¼å¼ï¼šä»context_management_eventsä¸­æå–
        if 'context_management_events' in data:
            for event in data['context_management_events']:
                event_type = event.get('type', '')
                if 'clear_tool_uses' in event_type:
                    stats['reset_count'] += 1
                elif 'clear_thinking' in event_type:
                    stats['thinking_reset_count'] += 1

        # å…ˆæ ¹æ®accuracyåˆ¤æ–­ï¼šå¦‚æœaccuracyæ˜¯1.0ï¼Œé»˜è®¤ç®—æ­£å¸¸ç»“æŸ
        if stats['accuracy'] == 1.0:
            stats['proper_ending'] = True

        # æå–API usageä¿¡æ¯ - å…¼å®¹ä¸‰ç§æ ¼å¼
        # ä¼˜å…ˆæ£€æŸ¥run_claude_api.pyæ ¼å¼ï¼ˆtotal_usageå­—æ®µï¼‰
        if "total_usage" in data:
            # run_claude_api.pyæ ¼å¼ï¼šç›´æ¥ä»total_usageæå–
            total_usage = data["total_usage"]
            stats['api_prompt_tokens'] = total_usage.get("input_tokens", 0)
            stats['api_completion_tokens'] = total_usage.get("output_tokens", 0)
            stats['api_total_cost'] = total_usage.get("total_cost_usd", 0.0) or 0.0

            # api_total_tokensä»æœ€åä¸€æ­¥çš„usage_trackingä¸­æå–ï¼ˆåŒ…å«æ‰€æœ‰tokenç±»å‹ï¼‰
            # å…¬å¼: input_tokens + cache_creation_input_tokens + cache_read_input_tokens + output_tokens
            if "usage_tracking" in data and len(data["usage_tracking"]) > 0:
                last_step = data["usage_tracking"][-1]
                stats['api_total_tokens'] = (
                    last_step.get("input_tokens", 0) +
                    last_step.get("cache_creation_input_tokens", 0) +
                    last_step.get("cache_read_input_tokens", 0) +
                    last_step.get("output_tokens", 0)
                )
            else:
                # å¦‚æœæ²¡æœ‰usage_trackingï¼Œå›é€€åˆ°ç®€å•è®¡ç®—
                stats['api_total_tokens'] = stats['api_prompt_tokens'] + stats['api_completion_tokens']

        elif "steps" in data and len(data["steps"]) > 0:
            try:
                # æ£€æµ‹æ˜¯å¦ä¸ºClaude Agent SDKæ ¼å¼
                first_step = data["steps"][0]
                is_claude_agent_format = "message" in first_step and "message_type" in first_step

                if is_claude_agent_format:
                    # Claude Agent SDKæ ¼å¼ï¼šä»usage_summaryæˆ–stepsä¸­çš„usageå­—æ®µæå–
                    if "usage_summary" in data:
                        usage_summary = data["usage_summary"]
                        # æ€»input tokens = input_tokens + cache_read + cache_creation
                        input_tokens = usage_summary.get("total_input_tokens", 0)
                        cache_read = usage_summary.get("cache_read_input_tokens", 0)
                        cache_creation = usage_summary.get("cache_creation_input_tokens", 0)
                        output_tokens = usage_summary.get("total_output_tokens", 0)

                        stats['api_prompt_tokens'] = input_tokens + cache_read + cache_creation
                        stats['api_completion_tokens'] = output_tokens
                        stats['api_total_tokens'] = stats['api_prompt_tokens'] + stats['api_completion_tokens']
                        stats['api_total_cost'] = usage_summary.get("total_cost_usd", 0.0) or 0.0
                    else:
                        # ä»stepsä¸­ç´¯åŠ usage
                        for step in data["steps"]:
                            if "usage" in step:
                                usage = step["usage"]
                                stats['api_prompt_tokens'] += usage.get("input_tokens", 0)
                                stats['api_completion_tokens'] += usage.get("output_tokens", 0)
                        stats['api_total_tokens'] = stats['api_prompt_tokens'] + stats['api_completion_tokens']
                else:
                    # åŸå§‹æ ¼å¼ï¼šä»action.raw_response.usageä¸­æå–
                    for step in data["steps"]:
                        if "action" in step and "raw_response" in step["action"]:
                            usage = step["action"]["raw_response"].get("usage", {})

                            # ç´¯åŠ tokensï¼ˆä»æ¯ä¸ªstepè·å–ï¼‰
                            step_total_tokens = usage.get("total_tokens", 0)
                            step_prompt_tokens = usage.get("prompt_tokens", 0)
                            step_completion_tokens = usage.get("completion_tokens", 0)

                            # å¯¹äºtokensï¼Œåªä½¿ç”¨æœ€åä¸€ä¸ªæœ‰æ•ˆçš„å€¼ï¼ˆå› ä¸ºAPIå¯èƒ½è¿”å›ç´¯ç§¯å€¼ï¼‰
                            if step_total_tokens > stats['api_total_tokens']:
                                stats['api_total_tokens'] = step_total_tokens
                                stats['api_prompt_tokens'] = step_prompt_tokens
                                stats['api_completion_tokens'] = step_completion_tokens

                            # ç´¯åŠ costï¼ˆæ¯ä¸ªstepçš„costéœ€è¦ç›¸åŠ ï¼‰
                            step_cost = usage.get("cost", 0.0)
                            if step_cost > 0:
                                stats['api_total_cost'] += step_cost

            except Exception as e:
                print(f"  Warning: æ— æ³•æå–usageä¿¡æ¯: {e}")
        
        # ç»Ÿè®¡æ¶ˆæ¯ - å…¼å®¹ä¸‰ç§æ ¼å¼
        messages = []
        is_claude_agent_format = False
        is_run_claude_api_format = False

        # æ£€æµ‹æ ¼å¼ç±»å‹
        # 1. ä¼˜å…ˆæ£€æµ‹run_claude_api.pyæ ¼å¼ï¼ˆæœ‰full_messages_historyæˆ–claude_messagesï¼‰
        if "full_messages_history" in data and data["full_messages_history"]:
            is_run_claude_api_format = True
        # 2. æ£€æµ‹æ˜¯å¦ä¸ºClaude Agent SDKæ ¼å¼
        elif "steps" in data and len(data["steps"]) > 0:
            first_step = data["steps"][0]
            is_claude_agent_format = "message" in first_step and "message_type" in first_step

        if is_run_claude_api_format:
            # run_claude_api.pyæ ¼å¼ï¼šä½¿ç”¨full_messages_history
            # full_messages_historyåŒ…å«å®Œæ•´çš„æ¶ˆæ¯å†å²
            messages = data.get("full_messages_history", [])

            # å¦‚æœfull_messages_historyä¸ºç©ºï¼Œå°è¯•ä½¿ç”¨claude_messages
            if not messages and "claude_messages" in data:
                messages = data["claude_messages"]

        elif is_claude_agent_format:
            # Claude Agent SDKæ ¼å¼ï¼šä»stepsä¸­æå–messages
            # å°†user_promptè½¬æ¢ä¸ºuser message
            if "user_prompt" in data:
                messages.append({
                    "role": "user",
                    "content": data["user_prompt"]
                })

            # ä»stepsä¸­æå–assistant/tool messages
            for step in data["steps"]:
                message = step.get("message", {})
                message_type = step.get("message_type", "")

                if message_type == "AssistantMessage":
                    messages.append({
                        "role": "assistant",
                        "content": message.get("content", []),
                        "tool_calls": []  # ä»contentä¸­çš„ToolUseBlockæå–
                    })
                elif message_type == "UserMessage":
                    # UserMessageå¯èƒ½åŒ…å«ToolResultBlock
                    content = message.get("content", [])
                    # æ£€æŸ¥æ˜¯å¦åŒ…å«ToolResultBlock
                    has_tool_result = False
                    if isinstance(content, list):
                        for item in content:
                            if isinstance(item, dict) and item.get("type") == "ToolResultBlock":
                                has_tool_result = True
                                break

                    if has_tool_result:
                        # è¿™æ˜¯tool result message
                        messages.append({
                            "role": "tool",
                            "content": content
                        })
                    else:
                        # è¿™æ˜¯æ™®é€šuser message
                        messages.append({
                            "role": "user",
                            "content": content
                        })
        else:
            # åŸå§‹æ ¼å¼ï¼šä½¿ç”¨full_messages_historyæˆ–final_messages
            if "full_messages_history" in data:
                full_history = data["full_messages_history"]

                # æ£€æŸ¥ç¬¬ä¸€ä¸ªæ¶ˆæ¯æ˜¯å¦ä¸ºuserï¼Œå¦‚æœä¸æ˜¯ï¼Œéœ€è¦ä»final_messagesä¸­å–ç¬¬ä¸€ä¸ªuseræ¶ˆæ¯
                if full_history and len(full_history) > 0:
                    first_message = full_history[0]
                    if first_message.get("role") != "user":
                        # ä»final_messagesä¸­æ‰¾ç¬¬ä¸€ä¸ªuseræ¶ˆæ¯
                        if "final_messages" in data:
                            final_messages = data["final_messages"]
                            for msg in final_messages:
                                if msg.get("role") == "user":
                                    # å°†ç¬¬ä¸€ä¸ªuseræ¶ˆæ¯åŠ å…¥åˆ°messageså¼€å¤´
                                    messages.append(msg)
                                    break
                        # ç„¶åæ·»åŠ full_messages_historyçš„æ‰€æœ‰æ¶ˆæ¯
                        messages.extend(full_history)
                    else:
                        # å¦‚æœç¬¬ä¸€ä¸ªæ¶ˆæ¯å°±æ˜¯userï¼Œç›´æ¥ä½¿ç”¨full_messages_history
                        messages = full_history
                else:
                    messages = full_history
            elif "final_messages" in data:
                # å¦‚æœæ²¡æœ‰full_messages_historyï¼Œå›é€€åˆ°ä½¿ç”¨final_messages
                messages = data["final_messages"]
        
        if messages:
            stats['total_messages'] = len(messages)
            
            for item in messages:
                role = item.get("role", "")
                
                # å¦‚æœé‡åˆ°assistantæ¶ˆæ¯ï¼Œè®°å½•å½“å‰ç´¯è®¡çš„tokensï¼ˆåœ¨å¤„ç†è¿™æ¡assistantæ¶ˆæ¯ä¹‹å‰ï¼‰
                if role == "assistant":
                    stats['tokens_before_each_assistant'].append({
                        'assistant_index': stats['assistant_messages'],  # ç¬¬å‡ ä¸ªassistantæ¶ˆæ¯
                        'cumulative_tokens': stats['all_content_tokens']  # ç´¯è®¡tokensæ•°
                    })
                
                # æ”¶é›†è¯¥æ¶ˆæ¯çš„æ‰€æœ‰å†…å®¹ç”¨äºç»Ÿè®¡
                all_text_parts = []
                
                # å¤„ç†ä¸åŒroleçš„å†…å®¹
                if role == "tool":
                    stats['tool_calls'] += 1
                    content = item.get("content", "")
                    # ä½¿ç”¨extract_text_from_contentå¤„ç†content
                    content_text = extract_text_from_content(content)
                    if content_text:
                        all_text_parts.append(content_text)
                        # å•ç‹¬ç»Ÿè®¡tool content
                        char_count = count_characters(content_text)
                        word_count = count_tokens_simple(content_text)
                        token_count = count_tokens_tiktoken(content_text, tokenizer)

                        stats['tool_content_chars'] += char_count
                        stats['tool_content_words'] += word_count
                        stats['tool_content_tokens'] += token_count
                        stats['tool_content_list'].append({
                            'chars': char_count,
                            'words': word_count,
                            'tokens': token_count
                        })

                elif role == "user":
                    stats['user_messages'] += 1
                    # Claude APIæ ¼å¼: useræ¶ˆæ¯çš„contentå¯èƒ½åŒ…å«tool_result
                    content = item.get("content", "")
                    if isinstance(content, list):
                        has_tool_result = False
                        for content_item in content:
                            if isinstance(content_item, dict) and content_item.get("type") == "tool_result":
                                has_tool_result = True
                                # ç»Ÿè®¡tool_resultä½œä¸ºtoolè°ƒç”¨ï¼ˆClaudeæ ¼å¼ï¼‰
                                stats['tool_calls'] += 1
                                tool_result_content = content_item.get("content", "")
                                if tool_result_content:
                                    tool_content_text = extract_text_from_content(tool_result_content)
                                    if tool_content_text:
                                        all_text_parts.append(tool_content_text)
                                        # å•ç‹¬ç»Ÿè®¡tool content
                                        char_count = count_characters(tool_content_text)
                                        word_count = count_tokens_simple(tool_content_text)
                                        token_count = count_tokens_tiktoken(tool_content_text, tokenizer)

                                        stats['tool_content_chars'] += char_count
                                        stats['tool_content_words'] += word_count
                                        stats['tool_content_tokens'] += token_count
                                        stats['tool_content_list'].append({
                                            'chars': char_count,
                                            'words': word_count,
                                            'tokens': token_count
                                        })
                            else:
                                # étool_resultçš„å†…å®¹ï¼ˆå¦‚æ™®é€štextï¼‰
                                content_text = extract_text_from_content(content_item)
                                if content_text:
                                    all_text_parts.append(content_text)
                    else:
                        # contentæ˜¯å­—ç¬¦ä¸²çš„æƒ…å†µ
                        content_text = extract_text_from_content(content)
                        if content_text:
                            all_text_parts.append(content_text)

                elif role == "assistant":
                    stats['assistant_messages'] += 1
                    # assistantéœ€è¦ç»Ÿè®¡: content, reasoning_content, tool_calls
                    content = item.get("content", "")
                    content_text = extract_text_from_content(content)
                    if content_text:
                        all_text_parts.append(content_text)

                    reasoning_content = item.get("reasoning_content", "")
                    if reasoning_content:
                        all_text_parts.append(extract_text_from_content(reasoning_content))

                    tool_calls = item.get("tool_calls", [])
                    if tool_calls:
                        # å°†tool_callsè½¬æ¢ä¸ºJSONå­—ç¬¦ä¸²æ¥è®¡ç®—tokens
                        try:
                            tool_calls_str = json.dumps(tool_calls, ensure_ascii=False)
                            all_text_parts.append(tool_calls_str)
                        except:
                            pass

                else:
                    # å…¶ä»–roleï¼Œç»Ÿè®¡content
                    content = item.get("content", "")
                    content_text = extract_text_from_content(content)
                    if content_text:
                        all_text_parts.append(content_text)
                
                # ç»Ÿè®¡è¯¥æ¶ˆæ¯çš„æ€»å†…å®¹åˆ°all_content
                if all_text_parts:
                    combined_text = "\n".join(all_text_parts)
                    char_count = count_characters(combined_text)
                    word_count = count_tokens_simple(combined_text)
                    token_count = count_tokens_tiktoken(combined_text, tokenizer)
                    
                    stats['all_content_chars'] += char_count
                    stats['all_content_words'] += word_count
                    stats['all_content_tokens'] += token_count
        
        # æ£€æŸ¥æœ€åä¸€æ¡æ¶ˆæ¯æ˜¯å¦åŒ…å«context length errorå’Œæ˜¯å¦æ­£å¸¸ç»“æŸ
        if messages and len(messages) > 0:
            last_message = messages[-1]
            if last_message.get("role") == "assistant":
                content = last_message.get("content", "")
                content_text = extract_text_from_content(content)
                # æ£€æŸ¥context length error
                if "maximum context length" in content_text or "context length" in content_text.lower():
                    stats['has_context_length_error'] = True

                # é¢å¤–æ£€æŸ¥æ˜¯å¦æœ‰claim_done_claim_doneçš„tool callï¼ˆå³ä½¿accuracyä¸æ˜¯1.0ä¹Ÿå¯èƒ½æ­£å¸¸ç»“æŸï¼‰
                tool_calls = last_message.get("tool_calls", [])
                if tool_calls:
                    for tool_call in tool_calls:
                        if isinstance(tool_call, dict):
                            function_info = tool_call.get("function", {})
                            if isinstance(function_info, dict):
                                function_name = function_info.get("name", "")
                                if function_name == "claim_done_claim_done":
                                    stats['proper_ending'] = True
                                    break

                # Claude Agent SDKæ ¼å¼: æ£€æŸ¥contentä¸­çš„ToolUseBlock
                if isinstance(content, list):
                    for item in content:
                        if isinstance(item, dict) and item.get("type") == "ToolUseBlock":
                            tool_name = item.get("name", "")
                            if "claim_done" in tool_name:
                                stats['proper_ending'] = True
                                break
        
        return stats
    except Exception as e:
        print(f"Error processing {json_path}: {e}")
        return None

# è§£æå‘½ä»¤è¡Œå‚æ•°
parser = argparse.ArgumentParser(description='åˆ†æbenchmarké…ç½®æ–‡ä»¶çš„ç»Ÿè®¡ä¿¡æ¯')
parser.add_argument('--input', '-i', type=str, required=False,
                    help='è¾“å…¥ç›®å½•è·¯å¾„ï¼ˆåŒ…å«config_*å­ç›®å½•çš„benchmarkç›®å½•ï¼‰')
parser.add_argument('--output', '-o', type=str, required=False,
                    help='è¾“å‡ºç›®å½•è·¯å¾„ï¼ˆä¿å­˜åˆ†æç»“æœçš„ç›®å½•ï¼Œé»˜è®¤ä¸ºè¾“å…¥ç›®å½•çš„çˆ¶ç›®å½•ï¼‰')
args = parser.parse_args()

def analyze_config_dir(config_path, tokenizer):
    """åˆ†ææ•´ä¸ªconfigç›®å½•ï¼ˆæ‰€æœ‰runï¼‰"""
    # æ‰¾åˆ°è¯¥configä¸‹çš„æ‰€æœ‰JSONæ–‡ä»¶
    json_files = sorted(glob.glob(os.path.join(config_path, "*.json")))
    
    # è¿‡æ»¤æ‰erroræ–‡ä»¶ï¼ˆæ–‡ä»¶åä¸­åŒ…å« "-error-" çš„æ–‡ä»¶æ˜¯ä¸­é—´é”™è¯¯çŠ¶æ€ï¼Œä¸åº”è®¡å…¥ç»Ÿè®¡ï¼‰
    original_count = len(json_files)
    json_files = [f for f in json_files if '-error-' not in os.path.basename(f)]
    filtered_count = original_count - len(json_files)
    if filtered_count > 0:
        print(f"  å·²è¿‡æ»¤ {filtered_count} ä¸ªerroræ–‡ä»¶")
    
    if not json_files:
        print(f"  Warning: æ²¡æœ‰æ‰¾åˆ°JSONæ–‡ä»¶")
        return None
    
    # å­˜å‚¨æ‰€æœ‰runçš„ç»Ÿè®¡ä¿¡æ¯
    all_runs = []
    
    for json_path in json_files:
        stats = analyze_config_file(json_path, tokenizer)
        if stats:
            all_runs.append(stats)
    
    if not all_runs:
        return None
    
    # è¿‡æ»¤æ‰æœ‰errorçš„runsç”¨äºtokenç»Ÿè®¡
    valid_runs_for_tokens = [r for r in all_runs if not r.get('has_error', False)]
    error_runs_count = len(all_runs) - len(valid_runs_for_tokens)
    if error_runs_count > 0:
        print(f"  âš ï¸  è·³è¿‡ {error_runs_count} ä¸ªå«errorçš„runçš„tokenç»Ÿè®¡")
    
    # æ±‡æ€»ç»Ÿè®¡
    config_summary = {
        'total_runs': len(all_runs),
        'success_runs': sum(1 for r in all_runs if r['completed']),
        'error_runs': sum(1 for r in all_runs if not r['completed']),
        'error_action_runs': error_runs_count,  # åŒ…å«error actionçš„runæ•°é‡
        'valid_runs_for_tokens': len(valid_runs_for_tokens),  # ç”¨äºtokenç»Ÿè®¡çš„æœ‰æ•ˆrunæ•°é‡
        'context_length_error_runs': sum(1 for r in all_runs if r.get('has_context_length_error', False)),
        'context_length_error_rate': sum(1 for r in all_runs if r.get('has_context_length_error', False)) / len(all_runs) if len(all_runs) > 0 else 0,
        'improper_ending_runs': sum(1 for r in all_runs if not r.get('proper_ending', False)),
        'improper_ending_rate': sum(1 for r in all_runs if not r.get('proper_ending', False)) / len(all_runs) if len(all_runs) > 0 else 0,
        
        # accuracyå’Œstepsç»Ÿè®¡ï¼ˆä½¿ç”¨æ‰€æœ‰runsï¼‰
        'accuracies': [r['accuracy'] for r in all_runs],
        'steps': [r['total_steps'] for r in all_runs],
        'avg_accuracy': sum(r['accuracy'] for r in all_runs) / len(all_runs),
        'avg_steps': sum(r['total_steps'] for r in all_runs) / len(all_runs),
        
        # resetã€summaryã€trimå’Œthinking_resetäº‹ä»¶ç»Ÿè®¡ï¼ˆä½¿ç”¨æ‰€æœ‰runsï¼‰
        'total_reset_count': sum(r['reset_count'] for r in all_runs),
        'total_summary_count': sum(r['summary_count'] for r in all_runs),
        'total_trim_count': sum(r['trim_count'] for r in all_runs),
        'total_thinking_reset_count': sum(r['thinking_reset_count'] for r in all_runs),
        'avg_reset_count': sum(r['reset_count'] for r in all_runs) / len(all_runs),
        'avg_summary_count': sum(r['summary_count'] for r in all_runs) / len(all_runs),
        'avg_trim_count': sum(r['trim_count'] for r in all_runs) / len(all_runs),
        'avg_thinking_reset_count': sum(r['thinking_reset_count'] for r in all_runs) / len(all_runs),
        
        # tokenç»Ÿè®¡ï¼ˆåªä½¿ç”¨æ²¡æœ‰errorçš„runsï¼‰
        'total_tool_calls': sum(r['tool_calls'] for r in valid_runs_for_tokens),
        'total_tool_content_tokens': sum(r['tool_content_tokens'] for r in valid_runs_for_tokens),
        'total_all_content_tokens': sum(r['all_content_tokens'] for r in valid_runs_for_tokens),
        'total_api_tokens': sum(r['api_total_tokens'] for r in valid_runs_for_tokens),
        'total_api_prompt_tokens': sum(r['api_prompt_tokens'] for r in valid_runs_for_tokens),
        'total_api_completion_tokens': sum(r['api_completion_tokens'] for r in valid_runs_for_tokens),
        'total_api_cost': sum(r['api_total_cost'] for r in valid_runs_for_tokens),
        'total_trimmed_tokens': sum(r['trimmed_tokens_total'] for r in valid_runs_for_tokens),  # è¢«trimæ‰çš„tokensæ€»æ•°
        'total_reset_tokens': sum(r['reset_tokens_total'] for r in valid_runs_for_tokens),  # è¢«resetæ‰çš„tokensæ€»æ•°
        'total_thinking_reset_tokens': sum(r['thinking_reset_tokens_total'] for r in valid_runs_for_tokens),  # è¢«thinking_resetæ‰çš„tokensæ€»æ•°
        'total_summary_tokens': sum(r['summary_tokens_total'] for r in valid_runs_for_tokens),  # è¢«summaryæ‰çš„tokensæ€»æ•°
        'total_api_tokens_with_trimmed': sum(r['api_total_tokens'] + r['trimmed_tokens_total'] for r in valid_runs_for_tokens),  # åŒ…å«è¢«trimæ‰çš„tokens
        'total_api_tokens_with_trimmed_and_reset': sum(r['api_total_tokens'] + r['trimmed_tokens_total'] + r['reset_tokens_total'] for r in valid_runs_for_tokens),  # åŒ…å«è¢«trimå’Œresetæ‰çš„tokens
        'total_api_tokens_with_all_removed': sum(r['api_total_tokens'] + r['trimmed_tokens_total'] + r['reset_tokens_total'] + r['thinking_reset_tokens_total'] + r['summary_tokens_total'] for r in valid_runs_for_tokens),  # åŒ…å«è¢«trimã€resetã€thinking_resetå’Œsummaryæ‰çš„tokens
        
        # å¹³å‡æ¯ä¸ªrunçš„ç»Ÿè®¡ï¼ˆåªä½¿ç”¨æ²¡æœ‰errorçš„runsï¼‰
        'avg_tool_calls': sum(r['tool_calls'] for r in valid_runs_for_tokens) / len(valid_runs_for_tokens) if len(valid_runs_for_tokens) > 0 else 0,
        'avg_tool_content_tokens': sum(r['tool_content_tokens'] for r in valid_runs_for_tokens) / len(valid_runs_for_tokens) if len(valid_runs_for_tokens) > 0 else 0,
        'avg_all_content_tokens': sum(r['all_content_tokens'] for r in valid_runs_for_tokens) / len(valid_runs_for_tokens) if len(valid_runs_for_tokens) > 0 else 0,
        'avg_api_tokens': sum(r['api_total_tokens'] for r in valid_runs_for_tokens) / len(valid_runs_for_tokens) if len(valid_runs_for_tokens) > 0 else 0,
        'avg_api_prompt_tokens': sum(r['api_prompt_tokens'] for r in valid_runs_for_tokens) / len(valid_runs_for_tokens) if len(valid_runs_for_tokens) > 0 else 0,
        'avg_api_completion_tokens': sum(r['api_completion_tokens'] for r in valid_runs_for_tokens) / len(valid_runs_for_tokens) if len(valid_runs_for_tokens) > 0 else 0,
        'avg_api_cost': sum(r['api_total_cost'] for r in valid_runs_for_tokens) / len(valid_runs_for_tokens) if len(valid_runs_for_tokens) > 0 else 0,
        'avg_trimmed_tokens': sum(r['trimmed_tokens_total'] for r in valid_runs_for_tokens) / len(valid_runs_for_tokens) if len(valid_runs_for_tokens) > 0 else 0,  # å¹³å‡æ¯ä¸ªrunè¢«trimæ‰çš„tokens
        'avg_reset_tokens': sum(r['reset_tokens_total'] for r in valid_runs_for_tokens) / len(valid_runs_for_tokens) if len(valid_runs_for_tokens) > 0 else 0,  # å¹³å‡æ¯ä¸ªrunè¢«resetæ‰çš„tokens
        'avg_thinking_reset_tokens': sum(r['thinking_reset_tokens_total'] for r in valid_runs_for_tokens) / len(valid_runs_for_tokens) if len(valid_runs_for_tokens) > 0 else 0,  # å¹³å‡æ¯ä¸ªrunè¢«thinking_resetæ‰çš„tokens
        'avg_summary_tokens': sum(r['summary_tokens_total'] for r in valid_runs_for_tokens) / len(valid_runs_for_tokens) if len(valid_runs_for_tokens) > 0 else 0,  # å¹³å‡æ¯ä¸ªrunè¢«summaryæ‰çš„tokens
        'avg_api_tokens_with_trimmed': sum(r['api_total_tokens'] + r['trimmed_tokens_total'] for r in valid_runs_for_tokens) / len(valid_runs_for_tokens) if len(valid_runs_for_tokens) > 0 else 0,  # åŒ…å«è¢«trimæ‰çš„å¹³å‡tokens
        'avg_api_tokens_with_trimmed_and_reset': sum(r['api_total_tokens'] + r['trimmed_tokens_total'] + r['reset_tokens_total'] for r in valid_runs_for_tokens) / len(valid_runs_for_tokens) if len(valid_runs_for_tokens) > 0 else 0,  # åŒ…å«è¢«trimå’Œresetæ‰çš„å¹³å‡tokens
        'avg_api_tokens_with_all_removed': sum(r['api_total_tokens'] + r['trimmed_tokens_total'] + r['reset_tokens_total'] + r['thinking_reset_tokens_total'] + r['summary_tokens_total'] for r in valid_runs_for_tokens) / len(valid_runs_for_tokens) if len(valid_runs_for_tokens) > 0 else 0,  # åŒ…å«è¢«trimã€resetã€thinking_resetå’Œsummaryæ‰çš„å¹³å‡tokens
        
        # æ‰€æœ‰runçš„è¯¦ç»†ä¿¡æ¯
        'runs': all_runs
    }
    
    # è®¡ç®—å¹³å‡æ¯ä¸ªtool callçš„tokens
    if config_summary['total_tool_calls'] > 0:
        config_summary['avg_tokens_per_tool_call'] = config_summary['total_tool_content_tokens'] / config_summary['total_tool_calls']
    else:
        config_summary['avg_tokens_per_tool_call'] = 0
    
    return config_summary

# ä¸»ç›®å½•è·¯å¾„
if args.input:
    base_dir = args.input
else:
    print("é”™è¯¯: å¿…é¡»æä¾› --input å‚æ•°æŒ‡å®šè¾“å…¥ç›®å½•")
    print("ä½¿ç”¨æ–¹æ³•: python ana_all_configs.py --input /path/to/benchmark/dir")
    sys.exit(1)

# éªŒè¯è¾“å…¥ç›®å½•æ˜¯å¦å­˜åœ¨
if not os.path.exists(base_dir):
    print(f"é”™è¯¯: è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {base_dir}")
    sys.exit(1)

if not os.path.isdir(base_dir):
    print(f"é”™è¯¯: è¾“å…¥è·¯å¾„ä¸æ˜¯ç›®å½•: {base_dir}")
    sys.exit(1)

# è¾“å‡ºç›®å½•è·¯å¾„
if args.output:
    output_dir = args.output
else:
    # é»˜è®¤ä¸ºè¾“å…¥ç›®å½•çš„çˆ¶ç›®å½•
    output_dir = os.path.dirname(base_dir)

# åˆ›å»ºè¾“å‡ºç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
os.makedirs(output_dir, exist_ok=True)

print(f"è¾“å…¥ç›®å½•: {base_dir}")
print(f"è¾“å‡ºç›®å½•: {output_dir}")
print("=" * 100)

# å°è¯•åŠ è½½summaryæ–‡ä»¶è·å–åˆ†ç»„ä¿¡æ¯
print("\næ­£åœ¨æ£€æŸ¥åˆ†ç»„ä¿¡æ¯...")
summary_info = load_summary_file(base_dir)
group_by_seed = False
config_groups = None

if summary_info:
    group_by_seed = summary_info.get('group_by_seed', False)
    config_groups = summary_info.get('config_groups', None)
    
    if group_by_seed and config_groups:
        print("\nğŸ“Š åˆ†ç»„ç»Ÿè®¡æ¨¡å¼")
        print(f"   é…ç½®ç»„æ•°é‡: {len(config_groups)}")
        for group_id, config_indices in sorted(config_groups.items()):
            print(f"   Group {group_id}: åŒ…å« config_{config_indices} (å…±{len(config_indices)}ä¸ªruns)")
    else:
        print("\nğŸ“Š ç‹¬ç«‹é…ç½®æ¨¡å¼")
else:
    print("   æœªæ‰¾åˆ°summaryæ–‡ä»¶ï¼Œä½¿ç”¨ç‹¬ç«‹é…ç½®æ¨¡å¼")

print("=" * 100)

# åˆå§‹åŒ–tokenizer
print("\næ­£åœ¨åˆå§‹åŒ–tokenizer...")
tokenizer = get_tokenizer()

# å­˜å‚¨æ‰€æœ‰configçš„ç»Ÿè®¡ç»“æœ
all_configs_stats = {}

# éå†æ‰€æœ‰configç›®å½•
config_dirs = sorted([d for d in os.listdir(base_dir) if d.startswith('config_')])

print(f"\næ‰¾åˆ° {len(config_dirs)} ä¸ªé…ç½®ç›®å½•\n")
print("=" * 100)

for config_dir in config_dirs:
    config_path = os.path.join(base_dir, config_dir)
    
    # æå–config_id
    config_id = int(config_dir.split('_')[1])
    
    # å¦‚æœæ˜¯åˆ†ç»„æ¨¡å¼ï¼Œæ˜¾ç¤ºåˆ†ç»„ä¿¡æ¯
    group_info = ""
    if group_by_seed and config_groups:
        # æ£€æŸ¥è¿™ä¸ªconfig_idå±äºå“ªä¸ªç»„
        for group_id, member_configs in config_groups.items():
            if config_id in member_configs:
                group_info = f" [Group {group_id}]"
                if len(member_configs) > 1:
                    group_info += f" (ä¸ config_{[c for c in member_configs if c != config_id]} åŒç»„)"
                break
    
    print(f"\næ­£åœ¨åˆ†æ {config_dir}{group_info}...")
    
    stats = analyze_config_dir(config_path, tokenizer)
    
    if stats:
        all_configs_stats[config_dir] = stats
        
        print(f"  æ€»Runæ•°: {stats['total_runs']}")
        print(f"  æˆåŠŸRunæ•°: {stats['success_runs']}")
        print(f"  å¤±è´¥Runæ•°: {stats['error_runs']}")
        print(f"  Context Length Erroræ•°: {stats['context_length_error_runs']} ({stats['context_length_error_rate']*100:.1f}%)")
        print(f"  éæ­£å¸¸ç»“æŸæ•°: {stats['improper_ending_runs']} ({stats['improper_ending_rate']*100:.1f}%)")
        print(f"  === ä»»åŠ¡æŒ‡æ ‡ ===")
        print(f"  å¹³å‡å‡†ç¡®åº¦: {stats['avg_accuracy']:.4f}")
        print(f"  å¹³å‡æ­¥æ•°: {stats['avg_steps']:.2f}")
        print(f"  å‡†ç¡®åº¦åˆ—è¡¨: {stats['accuracies']}")
        print(f"  æ­¥æ•°åˆ—è¡¨: {stats['steps']}")
        print(f"  === Reset & Summary & Trim & Thinking Resetç»Ÿè®¡ ===")
        print(f"  æ€»Resetæ¬¡æ•°: {stats['total_reset_count']}")
        print(f"  æ€»Summaryæ¬¡æ•°: {stats['total_summary_count']}")
        print(f"  æ€»Trimæ¬¡æ•°: {stats['total_trim_count']}")
        print(f"  æ€»Thinking Resetæ¬¡æ•°: {stats['total_thinking_reset_count']}")
        print(f"  å¹³å‡æ¯ä¸ªRunçš„Resetæ¬¡æ•°: {stats['avg_reset_count']:.2f}")
        print(f"  å¹³å‡æ¯ä¸ªRunçš„Summaryæ¬¡æ•°: {stats['avg_summary_count']:.2f}")
        print(f"  å¹³å‡æ¯ä¸ªRunçš„Trimæ¬¡æ•°: {stats['avg_trim_count']:.2f}")
        print(f"  å¹³å‡æ¯ä¸ªRunçš„Thinking Resetæ¬¡æ•°: {stats['avg_thinking_reset_count']:.2f}")
        print(f"  === API Usageï¼ˆæ‰€æœ‰runæ€»å’Œï¼‰ ===")
        print(f"  æ€»API Cost: ${stats['total_api_cost']:.6f} ğŸ’°ğŸ’°ğŸ’°")
        print(f"  å¹³å‡æ¯ä¸ªRunçš„API Cost: ${stats['avg_api_cost']:.6f}")
        print(f"  æ€»API Tokens: {stats['total_api_tokens']:,} â­â­â­")
        print(f"  å¹³å‡æ¯ä¸ªRunçš„API Tokens: {stats['avg_api_tokens']:,.2f}")
        print(f"  æ€»API Prompt Tokens: {stats['total_api_prompt_tokens']:,}")
        print(f"  æ€»API Completion Tokens: {stats['total_api_completion_tokens']:,}")
        print(f"  === Tool Contentç»Ÿè®¡ï¼ˆæ‰€æœ‰runæ€»å’Œï¼‰ ===")
        print(f"  æ€»Toolè°ƒç”¨æ•°: {stats['total_tool_calls']}")
        print(f"  æ€»Tool Content Tokens: {stats['total_tool_content_tokens']:,}")
        print(f"  å¹³å‡æ¯ä¸ªTool Callçš„Tokens: {stats['avg_tokens_per_tool_call']:.2f}")
        print(f"  æ€»æ‰€æœ‰Content Tokens: {stats['total_all_content_tokens']:,}")
        
        # æ˜¾ç¤ºtokenså˜åŒ–è¶‹åŠ¿ç»Ÿè®¡
        if stats['runs'] and any(run.get('tokens_before_each_assistant') for run in stats['runs']):
            all_progressions = []
            for run in stats['runs']:
                progression = run.get('tokens_before_each_assistant', [])
                if progression and len(progression) > 0:
                    all_progressions.append(progression)
            
            if all_progressions:
                print(f"  === Tokenså˜åŒ–è¶‹åŠ¿ ===")
                # è®¡ç®—å¹³å‡æ¯ä¸ªrunçš„assistantæ•°é‡
                avg_assistants = sum(len(p) for p in all_progressions) / len(all_progressions)
                print(f"  å¹³å‡æ¯ä¸ªRunçš„Assistantå›å¤æ•°: {avg_assistants:.1f}")
                
                # å¦‚æœæ‰€æœ‰runçš„assistantæ•°é‡ç›¸åŒï¼Œå¯ä»¥æ˜¾ç¤ºå¹³å‡tokenså˜åŒ–
                if len(set(len(p) for p in all_progressions)) == 1:
                    num_steps = len(all_progressions[0])
                    print(f"  å¹³å‡Tokenså¢é•¿è½¨è¿¹ (åœ¨æ¯æ¬¡assistantå›å¤å‰):")
                    for step in range(num_steps):
                        avg_tokens = sum(p[step]['cumulative_tokens'] for p in all_progressions) / len(all_progressions)
                        print(f"    Assistant #{step}: {avg_tokens:,.0f} tokens")

print("\n" + "=" * 100)
print("\n=== æ±‡æ€»ç»Ÿè®¡ ===\n")

# æ˜¾ç¤ºåˆ†ç»„æ¨¡å¼ä¿¡æ¯
if group_by_seed and config_groups:
    print(f"ğŸ“Š åˆ†ç»„ç»Ÿè®¡æ¨¡å¼")
    print(f"   å®é™…é…ç½®ç»„æ•°: {len(config_groups)}")
    print(f"   é…ç½®ç›®å½•æ€»æ•°: {len(config_dirs)}")
    print(f"\né…ç½®ç»„è¯¦æƒ…:")
    for group_id, member_configs in sorted(config_groups.items()):
        config_names = [f"config_{c}" for c in member_configs]
        print(f"   Group {group_id}: {', '.join(config_names)} (å…±{len(member_configs)}ä¸ªruns)")
    print()
else:
    print(f"ğŸ“Š ç‹¬ç«‹é…ç½®æ¨¡å¼")
    print(f"   é…ç½®æ€»æ•°: {len(config_dirs)}\n")

print("=" * 50)

# æ±‡æ€»ç»Ÿè®¡
total_runs = sum(s['total_runs'] for s in all_configs_stats.values())
total_success = sum(s['success_runs'] for s in all_configs_stats.values())
total_error = sum(s['error_runs'] for s in all_configs_stats.values())
total_context_length_errors = sum(s['context_length_error_runs'] for s in all_configs_stats.values())
total_improper_endings = sum(s['improper_ending_runs'] for s in all_configs_stats.values())
total_reset_events = sum(s['total_reset_count'] for s in all_configs_stats.values())
total_summary_events = sum(s['total_summary_count'] for s in all_configs_stats.values())
total_trim_events = sum(s['total_trim_count'] for s in all_configs_stats.values())
total_thinking_reset_events = sum(s['total_thinking_reset_count'] for s in all_configs_stats.values())

total_tool_calls = sum(s['total_tool_calls'] for s in all_configs_stats.values())
total_tool_tokens = sum(s['total_tool_content_tokens'] for s in all_configs_stats.values())
total_all_tokens = sum(s['total_all_content_tokens'] for s in all_configs_stats.values())
total_api_tokens = sum(s['total_api_tokens'] for s in all_configs_stats.values())
total_api_prompt_tokens = sum(s['total_api_prompt_tokens'] for s in all_configs_stats.values())
total_api_completion_tokens = sum(s['total_api_completion_tokens'] for s in all_configs_stats.values())
total_api_cost = sum(s['total_api_cost'] for s in all_configs_stats.values())
total_trimmed_tokens = sum(s['total_trimmed_tokens'] for s in all_configs_stats.values())
total_reset_tokens = sum(s['total_reset_tokens'] for s in all_configs_stats.values())
total_thinking_reset_tokens = sum(s['total_thinking_reset_tokens'] for s in all_configs_stats.values())
total_summary_tokens = sum(s['total_summary_tokens'] for s in all_configs_stats.values())
total_api_tokens_with_trimmed = sum(s['total_api_tokens_with_trimmed'] for s in all_configs_stats.values())
total_api_tokens_with_trimmed_and_reset = sum(s['total_api_tokens_with_trimmed_and_reset'] for s in all_configs_stats.values())
total_api_tokens_with_all_removed = sum(s['total_api_tokens_with_all_removed'] for s in all_configs_stats.values())

# æ”¶é›†å„configçš„ç»Ÿè®¡åˆ—è¡¨
avg_accuracy_list = [s['avg_accuracy'] for s in all_configs_stats.values()]
avg_steps_list = [s['avg_steps'] for s in all_configs_stats.values()]
tool_tokens_list = [s['total_tool_content_tokens'] for s in all_configs_stats.values()]
all_tokens_list = [s['total_all_content_tokens'] for s in all_configs_stats.values()]
avg_tokens_per_call_list = [s['avg_tokens_per_tool_call'] for s in all_configs_stats.values()]
api_tokens_list = [s['total_api_tokens'] for s in all_configs_stats.values()]
api_prompt_tokens_list = [s['total_api_prompt_tokens'] for s in all_configs_stats.values()]
api_completion_tokens_list = [s['total_api_completion_tokens'] for s in all_configs_stats.values()]
avg_api_tokens_per_run_list = [s['avg_api_tokens'] for s in all_configs_stats.values()]
api_cost_list = [s['total_api_cost'] for s in all_configs_stats.values()]
avg_api_cost_per_run_list = [s['avg_api_cost'] for s in all_configs_stats.values()]
trimmed_tokens_list = [s['total_trimmed_tokens'] for s in all_configs_stats.values()]
avg_trimmed_tokens_per_run_list = [s['avg_trimmed_tokens'] for s in all_configs_stats.values()]
reset_tokens_list = [s['total_reset_tokens'] for s in all_configs_stats.values()]
avg_reset_tokens_per_run_list = [s['avg_reset_tokens'] for s in all_configs_stats.values()]
thinking_reset_tokens_list = [s['total_thinking_reset_tokens'] for s in all_configs_stats.values()]
avg_thinking_reset_tokens_per_run_list = [s['avg_thinking_reset_tokens'] for s in all_configs_stats.values()]
summary_tokens_list = [s['total_summary_tokens'] for s in all_configs_stats.values()]
avg_summary_tokens_per_run_list = [s['avg_summary_tokens'] for s in all_configs_stats.values()]
api_tokens_with_trimmed_list = [s['total_api_tokens_with_trimmed'] for s in all_configs_stats.values()]
avg_api_tokens_with_trimmed_per_run_list = [s['avg_api_tokens_with_trimmed'] for s in all_configs_stats.values()]
api_tokens_with_trimmed_and_reset_list = [s['total_api_tokens_with_trimmed_and_reset'] for s in all_configs_stats.values()]
avg_api_tokens_with_trimmed_and_reset_per_run_list = [s['avg_api_tokens_with_trimmed_and_reset'] for s in all_configs_stats.values()]
api_tokens_with_all_removed_list = [s['total_api_tokens_with_all_removed'] for s in all_configs_stats.values()]
avg_api_tokens_with_all_removed_per_run_list = [s['avg_api_tokens_with_all_removed'] for s in all_configs_stats.values()]

total_error_action_runs = sum(s.get('error_action_runs', 0) for s in all_configs_stats.values())
total_valid_runs_for_tokens = sum(s.get('valid_runs_for_tokens', s['total_runs']) for s in all_configs_stats.values())

# è¿‡æ»¤æ‰æ‰€æœ‰runçš„tokenséƒ½ä¸º0çš„configï¼ˆç”¨äºè®¡ç®—æœ‰æ•ˆconfigçš„å¹³å‡tokensï¼‰
valid_configs_for_tokens = {k: v for k, v in all_configs_stats.items() if v.get('valid_runs_for_tokens', v['total_runs']) > 0}
excluded_configs_for_tokens = {k: v for k, v in all_configs_stats.items() if v.get('valid_runs_for_tokens', v['total_runs']) == 0}
num_excluded_configs = len(excluded_configs_for_tokens)

# ä¸ºæœ‰æ•ˆconfigsé‡æ–°è®¡ç®—tokenç›¸å…³çš„ç»Ÿè®¡åˆ—è¡¨
if valid_configs_for_tokens:
    valid_config_names = sorted(valid_configs_for_tokens.keys(), key=lambda x: int(x.split('_')[1]))
    valid_api_tokens_list = [valid_configs_for_tokens[k]['total_api_tokens'] for k in valid_config_names]
    valid_avg_api_tokens_per_run_list = [valid_configs_for_tokens[k]['avg_api_tokens'] for k in valid_config_names]
    valid_api_cost_list = [valid_configs_for_tokens[k]['total_api_cost'] for k in valid_config_names]
    valid_avg_api_cost_per_run_list = [valid_configs_for_tokens[k]['avg_api_cost'] for k in valid_config_names]
    valid_api_tokens_with_all_removed_list = [valid_configs_for_tokens[k]['total_api_tokens_with_all_removed'] for k in valid_config_names]
    valid_avg_api_tokens_with_all_removed_per_run_list = [valid_configs_for_tokens[k]['avg_api_tokens_with_all_removed'] for k in valid_config_names]
    valid_tool_tokens_list = [valid_configs_for_tokens[k]['total_tool_content_tokens'] for k in valid_config_names]
    valid_avg_tokens_per_call_list = [valid_configs_for_tokens[k]['avg_tokens_per_tool_call'] for k in valid_config_names]
    # Tool callsç›¸å…³ç»Ÿè®¡
    valid_tool_calls_list = [valid_configs_for_tokens[k]['total_tool_calls'] for k in valid_config_names]
    valid_avg_tool_calls_per_run_list = [valid_configs_for_tokens[k]['avg_tool_calls'] for k in valid_config_names]
    valid_avg_tool_content_tokens_per_run_list = [valid_configs_for_tokens[k]['avg_tool_content_tokens'] for k in valid_config_names]
else:
    valid_config_names = []
    valid_api_tokens_list = []
    valid_avg_api_tokens_per_run_list = []
    valid_api_cost_list = []
    valid_avg_api_cost_per_run_list = []
    valid_api_tokens_with_all_removed_list = []
    valid_avg_api_tokens_with_all_removed_per_run_list = []
    valid_tool_tokens_list = []
    valid_avg_tokens_per_call_list = []
    valid_tool_calls_list = []
    valid_avg_tool_calls_per_run_list = []
    valid_avg_tool_content_tokens_per_run_list = []

print(f"é…ç½®æ€»æ•°: {len(all_configs_stats)}")
print(f"æ€»Runæ•°: {total_runs}")
print(f"æ€»æˆåŠŸæ•°: {total_success}")
print(f"æ€»å¤±è´¥æ•°: {total_error}")
print(f"æ€»æˆåŠŸç‡: {total_success / total_runs * 100:.2f}%")
print(f"å«Error Actionçš„Runæ•°: {total_error_action_runs} (è¿™äº›runçš„tokenç»Ÿè®¡å·²è¢«æ’é™¤)")
print(f"ç”¨äºTokenç»Ÿè®¡çš„æœ‰æ•ˆRunæ•°: {total_valid_runs_for_tokens}")
print(f"å› æ‰€æœ‰runéƒ½å«errorè€Œè¢«æ’é™¤çš„Configæ•°: {num_excluded_configs}")
if num_excluded_configs > 0:
    print(f"  è¢«æ’é™¤çš„Configs: {', '.join(sorted(excluded_configs_for_tokens.keys(), key=lambda x: int(x.split('_')[1])))}")
print(f"ç”¨äºTokenç»Ÿè®¡çš„æœ‰æ•ˆConfigæ•°: {len(valid_configs_for_tokens)}")
print(f"æ€»Context Length Erroræ•°: {total_context_length_errors} ({total_context_length_errors / total_runs * 100:.2f}%)")
print(f"æ€»éæ­£å¸¸ç»“æŸæ•°: {total_improper_endings} ({total_improper_endings / total_runs * 100:.2f}%)")
print(f"æ€»Resetäº‹ä»¶æ•°: {total_reset_events} (å¹³å‡æ¯run: {total_reset_events / total_runs:.2f})")
print(f"æ€»Summaryäº‹ä»¶æ•°: {total_summary_events} (å¹³å‡æ¯run: {total_summary_events / total_runs:.2f})")
print(f"æ€»Trimäº‹ä»¶æ•°: {total_trim_events} (å¹³å‡æ¯run: {total_trim_events / total_runs:.2f})")
print(f"æ€»Thinking Resetäº‹ä»¶æ•°: {total_thinking_reset_events} (å¹³å‡æ¯run: {total_thinking_reset_events / total_runs:.2f})")

print(f"\n{'='*50}")
print(f"--- ä»»åŠ¡æŒ‡æ ‡ç»Ÿè®¡ â­â­â­ ---")
print(f"{'='*50}")
print(f"å¹³å‡å‡†ç¡®åº¦ï¼ˆæ‰€æœ‰configsï¼‰: {np.mean(avg_accuracy_list):.4f}")
print(f"å‡†ç¡®åº¦ä¸­ä½æ•°: {np.median(avg_accuracy_list):.4f}")
print(f"å‡†ç¡®åº¦æœ€å¤§å€¼: {max(avg_accuracy_list):.4f} ({config_dirs[avg_accuracy_list.index(max(avg_accuracy_list))]})")
print(f"å‡†ç¡®åº¦æœ€å°å€¼: {min(avg_accuracy_list):.4f} ({config_dirs[avg_accuracy_list.index(min(avg_accuracy_list))]})")
print(f"å‡†ç¡®åº¦æ ‡å‡†å·®: {np.std(avg_accuracy_list):.4f}")
print(f"\nå¹³å‡æ­¥æ•°ï¼ˆæ‰€æœ‰configsï¼‰: {np.mean(avg_steps_list):.2f}")
print(f"æ­¥æ•°ä¸­ä½æ•°: {np.median(avg_steps_list):.2f}")
print(f"æ­¥æ•°æœ€å¤§å€¼: {max(avg_steps_list):.2f} ({config_dirs[avg_steps_list.index(max(avg_steps_list))]})")
print(f"æ­¥æ•°æœ€å°å€¼: {min(avg_steps_list):.2f} ({config_dirs[avg_steps_list.index(min(avg_steps_list))]})")
print(f"æ­¥æ•°æ ‡å‡†å·®: {np.std(avg_steps_list):.2f}")

print(f"\n{'='*50}")
print(f"--- API Usage ç»Ÿè®¡ â­â­â­ ---")
print(f"{'='*50}")
print(f"APIæ€»Costï¼ˆæ‰€æœ‰runsï¼‰: ${total_api_cost:.6f} ğŸ’°ğŸ’°ğŸ’°")
print(f"å¹³å‡æ¯ä¸ªConfigçš„API Costï¼ˆæ‰€æœ‰runsæ€»å’Œï¼‰: ${np.mean(api_cost_list):.6f}")
print(f"å¹³å‡æ¯ä¸ªRunçš„API Cost: ${np.mean(avg_api_cost_per_run_list):.6f}")
print(f"æ¯ä¸ªConfigçš„API Costä¸­ä½æ•°: ${np.median(api_cost_list):.6f}")
print(f"æ¯ä¸ªConfigçš„API Costæœ€å¤§å€¼: ${max(api_cost_list):.6f} ({config_dirs[api_cost_list.index(max(api_cost_list))]})")
print(f"æ¯ä¸ªConfigçš„API Costæœ€å°å€¼: ${min(api_cost_list):.6f} ({config_dirs[api_cost_list.index(min(api_cost_list))]})")
print(f"æ¯ä¸ªConfigçš„API Costæ ‡å‡†å·®: ${np.std(api_cost_list):.6f}")
print(f"\nAPIæ€»Tokensæ•°ï¼ˆæ‰€æœ‰runsï¼‰: {total_api_tokens:,}")
print(f"APIæ€»Prompt Tokens: {total_api_prompt_tokens:,}")
print(f"APIæ€»Completion Tokens: {total_api_completion_tokens:,}")
print(f"\nå¹³å‡æ¯ä¸ªConfigçš„API Tokensï¼ˆæ‰€æœ‰runsæ€»å’Œï¼‰: {np.mean(api_tokens_list):,.2f}")
print(f"å¹³å‡æ¯ä¸ªRunçš„API Tokens: {np.mean(avg_api_tokens_per_run_list):,.2f}")
print(f"æ¯ä¸ªConfigçš„API Tokensä¸­ä½æ•°: {np.median(api_tokens_list):,.2f}")
print(f"æ¯ä¸ªConfigçš„API Tokensæœ€å¤§å€¼: {max(api_tokens_list):,} ({config_dirs[api_tokens_list.index(max(api_tokens_list))]})")
print(f"æ¯ä¸ªConfigçš„API Tokensæœ€å°å€¼: {min(api_tokens_list):,} ({config_dirs[api_tokens_list.index(min(api_tokens_list))]})")
print(f"æ¯ä¸ªConfigçš„API Tokensæ ‡å‡†å·®: {np.std(api_tokens_list):,.2f}")

print(f"\n--- Trimmed Tokens ç»Ÿè®¡ï¼ˆè¢«trimæ‰çš„tokensï¼‰âœ‚ï¸âœ‚ï¸âœ‚ï¸ ---")
print(f"è¢«Trimæ‰çš„æ€»Tokensæ•°ï¼ˆæ‰€æœ‰runsï¼‰: {total_trimmed_tokens:,}")
print(f"å¹³å‡æ¯ä¸ªRunè¢«Trimæ‰çš„Tokens: {np.mean(avg_trimmed_tokens_per_run_list):,.2f}")

print(f"\n--- Reset Tokens ç»Ÿè®¡ï¼ˆè¢«resetæ‰çš„tokensï¼‰ğŸ”„ğŸ”„ğŸ”„ ---")
print(f"è¢«Resetæ‰çš„æ€»Tokensæ•°ï¼ˆæ‰€æœ‰runsï¼‰: {total_reset_tokens:,}")
print(f"å¹³å‡æ¯ä¸ªRunè¢«Resetæ‰çš„Tokens: {np.mean(avg_reset_tokens_per_run_list):,.2f}")

print(f"\n--- Thinking Reset Tokens ç»Ÿè®¡ï¼ˆè¢«thinking_resetæ‰çš„tokensï¼‰ğŸ§ ğŸ§ ğŸ§  ---")
print(f"è¢«Thinking Resetæ‰çš„æ€»Tokensæ•°ï¼ˆæ‰€æœ‰runsï¼‰: {total_thinking_reset_tokens:,}")
print(f"å¹³å‡æ¯ä¸ªRunè¢«Thinking Resetæ‰çš„Tokens: {np.mean(avg_thinking_reset_tokens_per_run_list):,.2f}")

print(f"\n--- Summary Tokens ç»Ÿè®¡ï¼ˆè¢«summaryæ‰çš„tokensï¼‰ğŸ“‹ğŸ“‹ğŸ“‹ ---")
print(f"è¢«Summaryæ‰çš„æ€»Tokensæ•°ï¼ˆæ‰€æœ‰runsï¼‰: {total_summary_tokens:,}")
print(f"å¹³å‡æ¯ä¸ªRunè¢«Summaryæ‰çš„Tokens: {np.mean(avg_summary_tokens_per_run_list):,.2f}")

print(f"\n--- API Tokensï¼ˆåŒ…å«è¢«trimæ‰çš„ï¼‰ğŸ”¢ğŸ”¢ğŸ”¢ ---")
print(f"APIæ€»Tokensæ•°ï¼ˆåŒ…å«trimmedï¼Œæ‰€æœ‰runsï¼‰: {total_api_tokens_with_trimmed:,}")
print(f"å¹³å‡æ¯ä¸ªRunçš„API Tokensï¼ˆåŒ…å«trimmedï¼‰: {np.mean(avg_api_tokens_with_trimmed_per_run_list):,.2f}")
print(f"æ¯ä¸ªConfigçš„API Tokensï¼ˆåŒ…å«trimmedï¼‰ä¸­ä½æ•°: {np.median(api_tokens_with_trimmed_list):,.2f}")
if api_tokens_with_trimmed_list:
    print(f"æ¯ä¸ªConfigçš„API Tokensï¼ˆåŒ…å«trimmedï¼‰æœ€å¤§å€¼: {max(api_tokens_with_trimmed_list):,} ({config_dirs[api_tokens_with_trimmed_list.index(max(api_tokens_with_trimmed_list))]})")
    print(f"æ¯ä¸ªConfigçš„API Tokensï¼ˆåŒ…å«trimmedï¼‰æœ€å°å€¼: {min(api_tokens_with_trimmed_list):,} ({config_dirs[api_tokens_with_trimmed_list.index(min(api_tokens_with_trimmed_list))]})")
print(f"æ¯ä¸ªConfigçš„API Tokensï¼ˆåŒ…å«trimmedï¼‰æ ‡å‡†å·®: {np.std(api_tokens_with_trimmed_list):,.2f}")

print(f"\n--- API Tokensï¼ˆåŒ…å«è¢«trimå’Œresetæ‰çš„ï¼‰---")
print(f"APIæ€»Tokensæ•°ï¼ˆåŒ…å«trimmed+resetï¼Œæ‰€æœ‰runsï¼‰: {total_api_tokens_with_trimmed_and_reset:,}")
print(f"å¹³å‡æ¯ä¸ªRunçš„API Tokensï¼ˆåŒ…å«trimmed+resetï¼‰: {np.mean(avg_api_tokens_with_trimmed_and_reset_per_run_list):,.2f}")
print(f"æ¯ä¸ªConfigçš„API Tokensï¼ˆåŒ…å«trimmed+resetï¼‰ä¸­ä½æ•°: {np.median(api_tokens_with_trimmed_and_reset_list):,.2f}")
if api_tokens_with_trimmed_and_reset_list:
    print(f"æ¯ä¸ªConfigçš„API Tokensï¼ˆåŒ…å«trimmed+resetï¼‰æœ€å¤§å€¼: {max(api_tokens_with_trimmed_and_reset_list):,} ({config_dirs[api_tokens_with_trimmed_and_reset_list.index(max(api_tokens_with_trimmed_and_reset_list))]})")
    print(f"æ¯ä¸ªConfigçš„API Tokensï¼ˆåŒ…å«trimmed+resetï¼‰æœ€å°å€¼: {min(api_tokens_with_trimmed_and_reset_list):,} ({config_dirs[api_tokens_with_trimmed_and_reset_list.index(min(api_tokens_with_trimmed_and_reset_list))]})")
print(f"æ¯ä¸ªConfigçš„API Tokensï¼ˆåŒ…å«trimmed+resetï¼‰æ ‡å‡†å·®: {np.std(api_tokens_with_trimmed_and_reset_list):,.2f}")

print(f"\n--- API Tokensï¼ˆåŒ…å«è¢«trimã€resetå’Œthinking_resetæ‰çš„ï¼‰â­â­â­ ---")
print(f"APIæ€»Tokensæ•°ï¼ˆåŒ…å«trimmed+reset+thinking_resetï¼Œæ‰€æœ‰runsï¼‰: {total_api_tokens_with_all_removed:,} â­â­â­")
print(f"å¹³å‡æ¯ä¸ªRunçš„API Tokensï¼ˆåŒ…å«trimmed+reset+thinking_resetï¼‰: {np.mean(avg_api_tokens_with_all_removed_per_run_list):,.2f}")
print(f"æ¯ä¸ªConfigçš„API Tokensï¼ˆåŒ…å«all_removedï¼‰ä¸­ä½æ•°: {np.median(api_tokens_with_all_removed_list):,.2f}")
if api_tokens_with_all_removed_list:
    print(f"æ¯ä¸ªConfigçš„API Tokensï¼ˆåŒ…å«all_removedï¼‰æœ€å¤§å€¼: {max(api_tokens_with_all_removed_list):,} ({config_dirs[api_tokens_with_all_removed_list.index(max(api_tokens_with_all_removed_list))]})")
    print(f"æ¯ä¸ªConfigçš„API Tokensï¼ˆåŒ…å«all_removedï¼‰æœ€å°å€¼: {min(api_tokens_with_all_removed_list):,} ({config_dirs[api_tokens_with_all_removed_list.index(min(api_tokens_with_all_removed_list))]})")
print(f"æ¯ä¸ªConfigçš„API Tokensï¼ˆåŒ…å«all_removedï¼‰æ ‡å‡†å·®: {np.std(api_tokens_with_all_removed_list):,.2f}")

# ä»…æœ‰æ•ˆConfigçš„Tokenç»Ÿè®¡ï¼ˆæ’é™¤æ‰€æœ‰runéƒ½å«errorçš„configï¼‰
print(f"\n{'='*50}")
print(f"--- ä»…æœ‰æ•ˆConfigsçš„Tokenç»Ÿè®¡ï¼ˆæ’é™¤{num_excluded_configs}ä¸ªå…¨errorçš„configï¼‰ğŸ¯ğŸ¯ğŸ¯ ---")
print(f"{'='*50}")
if valid_configs_for_tokens:
    print(f"æœ‰æ•ˆConfigæ•°: {len(valid_configs_for_tokens)}")
    print(f"æœ‰æ•ˆConfigsçš„APIæ€»Tokens: {sum(valid_api_tokens_list):,}")
    print(f"æœ‰æ•ˆConfigsçš„å¹³å‡æ¯ä¸ªConfig API Tokens: {np.mean(valid_api_tokens_list):,.2f}")
    print(f"æœ‰æ•ˆConfigsçš„å¹³å‡æ¯ä¸ªRun API Tokens: {np.mean(valid_avg_api_tokens_per_run_list):,.2f} â­â­â­")
    print(f"æœ‰æ•ˆConfigsçš„API Tokensä¸­ä½æ•°: {np.median(valid_api_tokens_list):,.2f}")
    print(f"æœ‰æ•ˆConfigsçš„API Tokensæ ‡å‡†å·®: {np.std(valid_api_tokens_list):,.2f}")
    print(f"\næœ‰æ•ˆConfigsçš„APIæ€»Cost: ${sum(valid_api_cost_list):.6f}")
    print(f"æœ‰æ•ˆConfigsçš„å¹³å‡æ¯ä¸ªConfig API Cost: ${np.mean(valid_api_cost_list):.6f}")
    print(f"æœ‰æ•ˆConfigsçš„å¹³å‡æ¯ä¸ªRun API Cost: ${np.mean(valid_avg_api_cost_per_run_list):.6f} â­â­â­")
    print(f"\næœ‰æ•ˆConfigsçš„API Tokensï¼ˆåŒ…å«all_removedï¼‰æ€»æ•°: {sum(valid_api_tokens_with_all_removed_list):,}")
    print(f"æœ‰æ•ˆConfigsçš„å¹³å‡æ¯ä¸ªConfig API Tokensï¼ˆåŒ…å«all_removedï¼‰: {np.mean(valid_api_tokens_with_all_removed_list):,.2f}")
    print(f"æœ‰æ•ˆConfigsçš„å¹³å‡æ¯ä¸ªRun API Tokensï¼ˆåŒ…å«all_removedï¼‰: {np.mean(valid_avg_api_tokens_with_all_removed_per_run_list):,.2f} â­â­â­")
    
    # Tool callsç›¸å…³ç»Ÿè®¡
    print(f"\n--- æœ‰æ•ˆConfigsçš„Tool Callsç»Ÿè®¡ ğŸ”§ğŸ”§ğŸ”§ ---")
    print(f"æœ‰æ•ˆConfigsçš„Toolè°ƒç”¨æ€»æ¬¡æ•°: {sum(valid_tool_calls_list):,}")
    print(f"æœ‰æ•ˆConfigsçš„å¹³å‡æ¯ä¸ªConfig Toolè°ƒç”¨æ¬¡æ•°: {np.mean(valid_tool_calls_list):,.2f}")
    print(f"æœ‰æ•ˆConfigsçš„å¹³å‡æ¯ä¸ªRun Toolè°ƒç”¨æ¬¡æ•°: {np.mean(valid_avg_tool_calls_per_run_list):,.2f} â­â­â­")
    
    # Tool content tokensç›¸å…³ç»Ÿè®¡
    print(f"\n--- æœ‰æ•ˆConfigsçš„Tool Content Tokensç»Ÿè®¡ ğŸ“ğŸ“ğŸ“ ---")
    print(f"æœ‰æ•ˆConfigsçš„Tool Contentæ€»Tokens: {sum(valid_tool_tokens_list):,}")
    print(f"æœ‰æ•ˆConfigsçš„å¹³å‡æ¯ä¸ªConfig Tool Content Tokens: {np.mean(valid_tool_tokens_list):,.2f}")
    print(f"æœ‰æ•ˆConfigsçš„å¹³å‡æ¯ä¸ªRun Tool Content Tokens: {np.mean(valid_avg_tool_content_tokens_per_run_list):,.2f} â­â­â­")
    if sum(valid_tool_calls_list) > 0:
        print(f"æœ‰æ•ˆConfigsçš„å¹³å‡æ¯ä¸ªTool Callçš„Tokens: {sum(valid_tool_tokens_list) / sum(valid_tool_calls_list):,.2f} â­â­â­")
else:
    print(f"âš ï¸  æ²¡æœ‰æœ‰æ•ˆçš„Configç”¨äºTokenç»Ÿè®¡ï¼ˆæ‰€æœ‰Configçš„æ‰€æœ‰runéƒ½å«errorï¼‰")

print(f"\n{'='*50}")
print(f"--- Tool Content ç»Ÿè®¡ ---")
print(f"{'='*50}")
print(f"Toolè°ƒç”¨æ€»æ¬¡æ•°ï¼ˆæ‰€æœ‰runsï¼‰: {total_tool_calls:,}")
print(f"Tool Contentæ€»Tokensæ•°ï¼ˆæ‰€æœ‰runsï¼‰: {total_tool_tokens:,} â­")
if total_tool_calls > 0:
    print(f"å…¨å±€å¹³å‡æ¯ä¸ªTool Callçš„Tokens: {total_tool_tokens / total_tool_calls:.2f} â­â­")
else:
    print(f"å…¨å±€å¹³å‡æ¯ä¸ªTool Callçš„Tokens: N/A (æ²¡æœ‰Toolè°ƒç”¨) â­â­")
print(f"\nå¹³å‡æ¯ä¸ªConfigçš„Tool Tokensï¼ˆæ‰€æœ‰runsæ€»å’Œï¼‰: {np.mean(tool_tokens_list):,.2f}")
print(f"Tool Tokensä¸­ä½æ•°: {np.median(tool_tokens_list):,.2f}")
print(f"Tool Tokensæœ€å¤§å€¼: {max(tool_tokens_list):,} ({config_dirs[tool_tokens_list.index(max(tool_tokens_list))]})")
print(f"Tool Tokensæœ€å°å€¼: {min(tool_tokens_list):,} ({config_dirs[tool_tokens_list.index(min(tool_tokens_list))]})")
print(f"Tool Tokensæ ‡å‡†å·®: {np.std(tool_tokens_list):,.2f}")
print(f"\n--- æ¯ä¸ªTool Callå¹³å‡Tokensç»Ÿè®¡ â­â­ ---")
print(f"å„Configå¹³å‡æ¯ä¸ªTool Callçš„Tokens - å¹³å‡å€¼: {np.mean(avg_tokens_per_call_list):,.2f}")
print(f"å„Configå¹³å‡æ¯ä¸ªTool Callçš„Tokens - ä¸­ä½æ•°: {np.median(avg_tokens_per_call_list):,.2f}")
print(f"å„Configå¹³å‡æ¯ä¸ªTool Callçš„Tokens - æœ€å¤§å€¼: {max(avg_tokens_per_call_list):,.2f} ({config_dirs[avg_tokens_per_call_list.index(max(avg_tokens_per_call_list))]})")
print(f"å„Configå¹³å‡æ¯ä¸ªTool Callçš„Tokens - æœ€å°å€¼: {min(avg_tokens_per_call_list):,.2f} ({config_dirs[avg_tokens_per_call_list.index(min(avg_tokens_per_call_list))]})")
print(f"å„Configå¹³å‡æ¯ä¸ªTool Callçš„Tokens - æ ‡å‡†å·®: {np.std(avg_tokens_per_call_list):,.2f}")

print(f"\n--- æ‰€æœ‰Contentç»Ÿè®¡ ---")
print(f"æ‰€æœ‰Contentæ€»Tokensæ•°ï¼ˆæ‰€æœ‰runsï¼‰: {total_all_tokens:,} â­")
print(f"\nå¹³å‡æ¯ä¸ªConfigçš„æ€»Tokensï¼ˆæ‰€æœ‰runsæ€»å’Œï¼‰: {np.mean(all_tokens_list):,.2f} â­")
print(f"æ€»Tokensä¸­ä½æ•°: {np.median(all_tokens_list):,.2f}")
print(f"æ€»Tokensæœ€å¤§å€¼: {max(all_tokens_list):,} ({config_dirs[all_tokens_list.index(max(all_tokens_list))]})")
print(f"æ€»Tokensæœ€å°å€¼: {min(all_tokens_list):,} ({config_dirs[all_tokens_list.index(min(all_tokens_list))]})")
print(f"æ€»Tokensæ ‡å‡†å·®: {np.std(all_tokens_list):,.2f}")

# æŒ‰Resetæ¬¡æ•°æ’åºæ˜¾ç¤º
print(f"\n{'='*80}")
print(f"--- æŒ‰Resetæ¬¡æ•°æ’åºçš„Configåˆ—è¡¨ ğŸ”„ğŸ”„ğŸ”„ ---")
print(f"{'='*80}")
sorted_configs_reset = sorted(all_configs_stats.items(), key=lambda x: x[1]['total_reset_count'], reverse=True)
for i, (config_name, stats) in enumerate(sorted_configs_reset, 1):
    print(f"{i:2d}. {config_name:12s}: Reset: {stats['total_reset_count']:3d}æ¬¡ (å¹³å‡{stats['avg_reset_count']:.2f}/run) | Summary: {stats['total_summary_count']:3d}æ¬¡ (å¹³å‡{stats['avg_summary_count']:.2f}/run) | Trim: {stats['total_trim_count']:3d}æ¬¡ (å¹³å‡{stats['avg_trim_count']:.2f}/run) | Thinking Reset: {stats['total_thinking_reset_count']:3d}æ¬¡ (å¹³å‡{stats['avg_thinking_reset_count']:.2f}/run) | å‡†ç¡®åº¦: {stats['avg_accuracy']:.4f}")

# æŒ‰Summaryæ¬¡æ•°æ’åºæ˜¾ç¤º
print(f"\n{'='*80}")
print(f"--- æŒ‰Summaryæ¬¡æ•°æ’åºçš„Configåˆ—è¡¨ ğŸ“ğŸ“ğŸ“ ---")
print(f"{'='*80}")
sorted_configs_summary = sorted(all_configs_stats.items(), key=lambda x: x[1]['total_summary_count'], reverse=True)
for i, (config_name, stats) in enumerate(sorted_configs_summary, 1):
    print(f"{i:2d}. {config_name:12s}: Summary: {stats['total_summary_count']:3d}æ¬¡ (å¹³å‡{stats['avg_summary_count']:.2f}/run) | Reset: {stats['total_reset_count']:3d}æ¬¡ (å¹³å‡{stats['avg_reset_count']:.2f}/run) | Trim: {stats['total_trim_count']:3d}æ¬¡ (å¹³å‡{stats['avg_trim_count']:.2f}/run) | Thinking Reset: {stats['total_thinking_reset_count']:3d}æ¬¡ (å¹³å‡{stats['avg_thinking_reset_count']:.2f}/run) | å‡†ç¡®åº¦: {stats['avg_accuracy']:.4f}")

# æŒ‰Trimæ¬¡æ•°æ’åºæ˜¾ç¤º
print(f"\n{'='*80}")
print(f"--- æŒ‰Trimæ¬¡æ•°æ’åºçš„Configåˆ—è¡¨ âœ‚ï¸âœ‚ï¸âœ‚ï¸ ---")
print(f"{'='*80}")
sorted_configs_trim = sorted(all_configs_stats.items(), key=lambda x: x[1]['total_trim_count'], reverse=True)
for i, (config_name, stats) in enumerate(sorted_configs_trim, 1):
    print(f"{i:2d}. {config_name:12s}: Trim: {stats['total_trim_count']:3d}æ¬¡ (å¹³å‡{stats['avg_trim_count']:.2f}/run) | Reset: {stats['total_reset_count']:3d}æ¬¡ (å¹³å‡{stats['avg_reset_count']:.2f}/run) | Summary: {stats['total_summary_count']:3d}æ¬¡ (å¹³å‡{stats['avg_summary_count']:.2f}/run) | Thinking Reset: {stats['total_thinking_reset_count']:3d}æ¬¡ (å¹³å‡{stats['avg_thinking_reset_count']:.2f}/run) | å‡†ç¡®åº¦: {stats['avg_accuracy']:.4f}")

# æŒ‰Thinking Resetæ¬¡æ•°æ’åºæ˜¾ç¤º
print(f"\n{'='*80}")
print(f"--- æŒ‰Thinking Resetæ¬¡æ•°æ’åºçš„Configåˆ—è¡¨ ğŸ§ ğŸ§ ğŸ§  ---")
print(f"{'='*80}")
sorted_configs_thinking_reset = sorted(all_configs_stats.items(), key=lambda x: x[1]['total_thinking_reset_count'], reverse=True)
for i, (config_name, stats) in enumerate(sorted_configs_thinking_reset, 1):
    print(f"{i:2d}. {config_name:12s}: Thinking Reset: {stats['total_thinking_reset_count']:3d}æ¬¡ (å¹³å‡{stats['avg_thinking_reset_count']:.2f}/run) | Reset: {stats['total_reset_count']:3d}æ¬¡ (å¹³å‡{stats['avg_reset_count']:.2f}/run) | Summary: {stats['total_summary_count']:3d}æ¬¡ (å¹³å‡{stats['avg_summary_count']:.2f}/run) | Trim: {stats['total_trim_count']:3d}æ¬¡ (å¹³å‡{stats['avg_trim_count']:.2f}/run) | å‡†ç¡®åº¦: {stats['avg_accuracy']:.4f}")

# æŒ‰Improper Ending Rateæ’åºæ˜¾ç¤º
print(f"\n{'='*80}")
print(f"--- æŒ‰éæ­£å¸¸ç»“æŸæ¯”ä¾‹æ’åºçš„Configåˆ—è¡¨ âš ï¸âš ï¸âš ï¸ ---")
print(f"{'='*80}")
sorted_configs_improper = sorted(all_configs_stats.items(), key=lambda x: x[1]['improper_ending_rate'], reverse=True)
for i, (config_name, stats) in enumerate(sorted_configs_improper, 1):
    print(f"{i:2d}. {config_name:12s}: éæ­£å¸¸ç»“æŸ: {stats['improper_ending_runs']}/{stats['total_runs']} ({stats['improper_ending_rate']*100:.1f}%) | å‡†ç¡®åº¦: {stats['avg_accuracy']:.4f} | å¹³å‡æ­¥æ•°: {stats['avg_steps']:6.2f}")

# æŒ‰Context Length Error Rateæ’åºæ˜¾ç¤º
print(f"\n{'='*80}")
print(f"--- æŒ‰Context Length Erroræ¯”ä¾‹æ’åºçš„Configåˆ—è¡¨ ğŸš¨ğŸš¨ğŸš¨ ---")
print(f"{'='*80}")
sorted_configs_ctx_err = sorted(all_configs_stats.items(), key=lambda x: x[1]['context_length_error_rate'], reverse=True)
for i, (config_name, stats) in enumerate(sorted_configs_ctx_err, 1):
    print(f"{i:2d}. {config_name:12s}: Context Length Error: {stats['context_length_error_runs']}/{stats['total_runs']} ({stats['context_length_error_rate']*100:.1f}%) | å‡†ç¡®åº¦: {stats['avg_accuracy']:.4f} | å¹³å‡æ­¥æ•°: {stats['avg_steps']:6.2f}")

# æŒ‰å‡†ç¡®åº¦æ’åºæ˜¾ç¤º
print(f"\n{'='*80}")
print(f"--- æŒ‰å¹³å‡å‡†ç¡®åº¦æ’åºçš„Configåˆ—è¡¨ â­â­â­ ---")
print(f"{'='*80}")
sorted_configs_acc = sorted(all_configs_stats.items(), key=lambda x: x[1]['avg_accuracy'], reverse=True)
for i, (config_name, stats) in enumerate(sorted_configs_acc, 1):
    ctx_err_str = f"CtxErr: {stats['context_length_error_runs']}/{stats['total_runs']} ({stats['context_length_error_rate']*100:.1f}%)"
    improper_str = f"éæ­£å¸¸ç»“æŸ: {stats['improper_ending_runs']}/{stats['total_runs']} ({stats['improper_ending_rate']*100:.1f}%)"
    reset_summary_trim_str = f"Reset: {stats['total_reset_count']}æ¬¡ | Summary: {stats['total_summary_count']}æ¬¡ | Trim: {stats['total_trim_count']}æ¬¡ | Thinking Reset: {stats['total_thinking_reset_count']}æ¬¡"
    print(f"{i:2d}. {config_name:12s}: å‡†ç¡®åº¦: {stats['avg_accuracy']:.4f} | å¹³å‡æ­¥æ•°: {stats['avg_steps']:6.2f} | æˆåŠŸ/æ€»æ•°: {stats['success_runs']}/{stats['total_runs']} | {improper_str} | {ctx_err_str} | {reset_summary_trim_str} | API cost: ${stats['total_api_cost']:.6f}")

# æŒ‰API Total Costæ’åºæ˜¾ç¤º
print(f"\n{'='*80}")
print(f"--- æŒ‰API Total Costæ’åºçš„Configåˆ—è¡¨ ğŸ’°ğŸ’°ğŸ’° ---")
print(f"{'='*80}")
sorted_configs_cost = sorted(all_configs_stats.items(), key=lambda x: x[1]['total_api_cost'], reverse=True)
for i, (config_name, stats) in enumerate(sorted_configs_cost, 1):
    print(f"{i:2d}. {config_name:12s}: APIæ€»cost: ${stats['total_api_cost']:9.6f} | å¹³å‡æ¯run: ${stats['avg_api_cost']:9.6f} | API tokens: {stats['total_api_tokens']:8,} | Toolè°ƒç”¨: {stats['total_tool_calls']:3d}æ¬¡")

# æŒ‰API Total Tokensæ’åºæ˜¾ç¤º
print(f"\n{'='*80}")
print(f"--- æŒ‰API Total Tokensæ’åºçš„Configåˆ—è¡¨ â­â­â­ ---")
print(f"{'='*80}")
sorted_configs_api = sorted(all_configs_stats.items(), key=lambda x: x[1]['total_api_tokens'], reverse=True)
for i, (config_name, stats) in enumerate(sorted_configs_api, 1):
    print(f"{i:2d}. {config_name:12s}: APIæ€»tokens: {stats['total_api_tokens']:8,} | å¹³å‡æ¯run: {stats['avg_api_tokens']:8,.2f} | Prompt: {stats['total_api_prompt_tokens']:8,} | Completion: {stats['total_api_completion_tokens']:7,} | Toolè°ƒç”¨: {stats['total_tool_calls']:3d}æ¬¡")

# æŒ‰Tool Content Tokensæ’åºæ˜¾ç¤º
print(f"\n{'='*80}")
print(f"--- æŒ‰Tool Content Tokensæ•°æ’åºçš„Configåˆ—è¡¨ ---")
print(f"{'='*80}")
sorted_configs = sorted(all_configs_stats.items(), key=lambda x: x[1]['total_tool_content_tokens'], reverse=True)
for i, (config_name, stats) in enumerate(sorted_configs, 1):
    print(f"{i:2d}. {config_name:12s}: Tool Content: {stats['total_tool_content_tokens']:8,} tokens (å¹³å‡æ¯call: {stats['avg_tokens_per_tool_call']:7.2f}) | Toolè°ƒç”¨: {stats['total_tool_calls']:3d}æ¬¡")

# æŒ‰å¹³å‡æ¯ä¸ªtool callçš„tokensæ’åºæ˜¾ç¤º
print(f"\n{'='*80}")
print(f"--- æŒ‰å¹³å‡æ¯ä¸ªTool Callçš„Tokensæ’åºçš„Configåˆ—è¡¨ ---")
print(f"{'='*80}")
sorted_configs_avg = sorted(all_configs_stats.items(), key=lambda x: x[1]['avg_tokens_per_tool_call'], reverse=True)
for i, (config_name, stats) in enumerate(sorted_configs_avg, 1):
    print(f"{i:2d}. {config_name:12s}: å¹³å‡ {stats['avg_tokens_per_tool_call']:7.2f} tokens/call | æ€»Tool Content tokens: {stats['total_tool_content_tokens']:8,} | Toolè°ƒç”¨: {stats['total_tool_calls']:3d}æ¬¡")

print("\n" + "=" * 100)

# ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
import datetime
output_filename = f"analysis_results_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
output_path = os.path.join(output_dir, output_filename)

# å‡†å¤‡è¦ä¿å­˜çš„æ•°æ®ï¼ˆç§»é™¤runsè¯¦ç»†ä¿¡æ¯ä¸­çš„å¤§é‡å†…å®¹ï¼Œåªä¿ç•™å…³é”®æŒ‡æ ‡ï¼‰
save_data = {
    "analysis_time": datetime.datetime.now().isoformat(),
    "base_directory": base_dir,
    "grouping_info": {
        "group_by_seed": group_by_seed,
        "config_groups": {str(k): v for k, v in config_groups.items()} if config_groups else None,
        "num_groups": len(config_groups) if config_groups else len(all_configs_stats)
    },
    "summary": {
        "total_configs": len(all_configs_stats),
        "total_runs": total_runs,
        "total_success": total_success,
        "total_error": total_error,
        "total_error_action_runs": sum(s.get('error_action_runs', 0) for s in all_configs_stats.values()),  # åŒ…å«error actionçš„runæ•°é‡
        "total_valid_runs_for_tokens": sum(s.get('valid_runs_for_tokens', s['total_runs']) for s in all_configs_stats.values()),  # ç”¨äºtokenç»Ÿè®¡çš„æœ‰æ•ˆrunæ•°é‡
        "success_rate": total_success / total_runs if total_runs > 0 else 0,
        "total_context_length_errors": total_context_length_errors,
        "context_length_error_rate": total_context_length_errors / total_runs if total_runs > 0 else 0,
        "total_improper_endings": total_improper_endings,
        "improper_ending_rate": total_improper_endings / total_runs if total_runs > 0 else 0,
        "total_reset_events": total_reset_events,
        "total_summary_events": total_summary_events,
        "total_trim_events": total_trim_events,
        "total_thinking_reset_events": total_thinking_reset_events,
        "avg_reset_per_run": total_reset_events / total_runs if total_runs > 0 else 0,
        "avg_summary_per_run": total_summary_events / total_runs if total_runs > 0 else 0,
        "avg_trim_per_run": total_trim_events / total_runs if total_runs > 0 else 0,
        "avg_thinking_reset_per_run": total_thinking_reset_events / total_runs if total_runs > 0 else 0,
        
        # ä»»åŠ¡æŒ‡æ ‡
        "avg_accuracy": float(np.mean(avg_accuracy_list)),
        "median_accuracy": float(np.median(avg_accuracy_list)),
        "avg_steps": float(np.mean(avg_steps_list)),
        "median_steps": float(np.median(avg_steps_list)),
        
        # API tokens
        "total_api_tokens": total_api_tokens,
        "total_api_prompt_tokens": total_api_prompt_tokens,
        "total_api_completion_tokens": total_api_completion_tokens,
        "avg_api_tokens_per_config": float(np.mean(api_tokens_list)),
        "avg_api_tokens_per_run": float(np.mean(avg_api_tokens_per_run_list)),
        
        # API cost
        "total_api_cost": float(total_api_cost),
        "avg_api_cost_per_config": float(np.mean(api_cost_list)),
        "avg_api_cost_per_run": float(np.mean(avg_api_cost_per_run_list)),
        
        # Tool content
        "total_tool_calls": total_tool_calls,
        "total_tool_content_tokens": total_tool_tokens,
        "avg_tokens_per_tool_call": total_tool_tokens / total_tool_calls if total_tool_calls > 0 else 0,
        "total_all_content_tokens": total_all_tokens,
        
        # Trimmed tokens
        "total_trimmed_tokens": total_trimmed_tokens,
        "avg_trimmed_tokens_per_run": float(np.mean(avg_trimmed_tokens_per_run_list)),
        "total_api_tokens_with_trimmed": total_api_tokens_with_trimmed,
        "avg_api_tokens_with_trimmed_per_run": float(np.mean(avg_api_tokens_with_trimmed_per_run_list)),
        
        # Reset tokens
        "total_reset_tokens": total_reset_tokens,
        "avg_reset_tokens_per_run": float(np.mean(avg_reset_tokens_per_run_list)),
        "total_api_tokens_with_trimmed_and_reset": total_api_tokens_with_trimmed_and_reset,
        "avg_api_tokens_with_trimmed_and_reset_per_run": float(np.mean(avg_api_tokens_with_trimmed_and_reset_per_run_list)),
        
        # Thinking reset tokens
        "total_thinking_reset_tokens": total_thinking_reset_tokens,
        "avg_thinking_reset_tokens_per_run": float(np.mean(avg_thinking_reset_tokens_per_run_list)),
        
        # Summary tokens
        "total_summary_tokens": total_summary_tokens,
        "avg_summary_tokens_per_run": float(np.mean(avg_summary_tokens_per_run_list)),
        
        "total_api_tokens_with_all_removed": total_api_tokens_with_all_removed,
        "avg_api_tokens_with_all_removed_per_run": float(np.mean(avg_api_tokens_with_all_removed_per_run_list)),
        
        # ä»…æœ‰æ•ˆConfigsçš„ç»Ÿè®¡ï¼ˆæ’é™¤æ‰€æœ‰runéƒ½å«errorçš„configï¼‰
        "num_excluded_configs_for_tokens": num_excluded_configs,
        "excluded_configs_for_tokens": list(excluded_configs_for_tokens.keys()) if excluded_configs_for_tokens else [],
        "num_valid_configs_for_tokens": len(valid_configs_for_tokens),
        "valid_configs_total_api_tokens": sum(valid_api_tokens_list) if valid_api_tokens_list else 0,
        "valid_configs_avg_api_tokens_per_config": float(np.mean(valid_api_tokens_list)) if valid_api_tokens_list else 0,
        "valid_configs_avg_api_tokens_per_run": float(np.mean(valid_avg_api_tokens_per_run_list)) if valid_avg_api_tokens_per_run_list else 0,
        "valid_configs_total_api_cost": sum(valid_api_cost_list) if valid_api_cost_list else 0,
        "valid_configs_avg_api_cost_per_config": float(np.mean(valid_api_cost_list)) if valid_api_cost_list else 0,
        "valid_configs_avg_api_cost_per_run": float(np.mean(valid_avg_api_cost_per_run_list)) if valid_avg_api_cost_per_run_list else 0,
        "valid_configs_total_api_tokens_with_all_removed": sum(valid_api_tokens_with_all_removed_list) if valid_api_tokens_with_all_removed_list else 0,
        "valid_configs_avg_api_tokens_with_all_removed_per_config": float(np.mean(valid_api_tokens_with_all_removed_list)) if valid_api_tokens_with_all_removed_list else 0,
        "valid_configs_avg_api_tokens_with_all_removed_per_run": float(np.mean(valid_avg_api_tokens_with_all_removed_per_run_list)) if valid_avg_api_tokens_with_all_removed_per_run_list else 0,
        
        # æœ‰æ•ˆConfigsçš„Tool Callsç»Ÿè®¡
        "valid_configs_total_tool_calls": sum(valid_tool_calls_list) if valid_tool_calls_list else 0,
        "valid_configs_avg_tool_calls_per_config": float(np.mean(valid_tool_calls_list)) if valid_tool_calls_list else 0,
        "valid_configs_avg_tool_calls_per_run": float(np.mean(valid_avg_tool_calls_per_run_list)) if valid_avg_tool_calls_per_run_list else 0,
        
        # æœ‰æ•ˆConfigsçš„Tool Content Tokensç»Ÿè®¡
        "valid_configs_total_tool_content_tokens": sum(valid_tool_tokens_list) if valid_tool_tokens_list else 0,
        "valid_configs_avg_tool_content_tokens_per_config": float(np.mean(valid_tool_tokens_list)) if valid_tool_tokens_list else 0,
        "valid_configs_avg_tool_content_tokens_per_run": float(np.mean(valid_avg_tool_content_tokens_per_run_list)) if valid_avg_tool_content_tokens_per_run_list else 0,
        "valid_configs_avg_tokens_per_tool_call": sum(valid_tool_tokens_list) / sum(valid_tool_calls_list) if valid_tool_calls_list and sum(valid_tool_calls_list) > 0 else 0,
    },
    "configs": {}
}

# ä¸ºæ¯ä¸ªconfigæ·»åŠ æ±‡æ€»æ•°æ®ï¼ˆåŒ…å«æ¯ä¸ªrunçš„è¯¦ç»†ä¿¡æ¯ï¼‰
for config_name, stats in all_configs_stats.items():
    # æå–æ¯ä¸ªrunçš„å…³é”®æŒ‡æ ‡
    runs_detail = []
    for idx, run in enumerate(stats['runs']):
        run_info = {
            "run_index": idx,
            "accuracy": run['accuracy'],
            "total_steps": run['total_steps'],
            "completed": run['completed'],
            "has_context_length_error": run.get('has_context_length_error', False),
            "proper_ending": run.get('proper_ending', False),
            "has_error": run.get('has_error', False),  # æ˜¯å¦åŒ…å«error actionï¼ˆç”¨äºæ’é™¤tokenç»Ÿè®¡ï¼‰
            "reset_count": run.get('reset_count', 0),
            "summary_count": run.get('summary_count', 0),
            "trim_count": run.get('trim_count', 0),
            "thinking_reset_count": run.get('thinking_reset_count', 0),
            "total_messages": run['total_messages'],
            "tool_calls": run['tool_calls'],
            "user_messages": run['user_messages'],
            "assistant_messages": run['assistant_messages'],
            "tool_content_tokens": run['tool_content_tokens'],
            "all_content_tokens": run['all_content_tokens'],
            "api_total_tokens": run['api_total_tokens'],
            "api_prompt_tokens": run['api_prompt_tokens'],
            "api_completion_tokens": run['api_completion_tokens'],
            "api_total_cost": run['api_total_cost'],
            "trimmed_tokens_total": run.get('trimmed_tokens_total', 0),  # è¢«trimæ‰çš„tokensæ€»æ•°
            "reset_tokens_total": run.get('reset_tokens_total', 0),  # è¢«resetæ‰çš„tokensæ€»æ•°
            "thinking_reset_tokens_total": run.get('thinking_reset_tokens_total', 0),  # è¢«thinking_resetæ‰çš„tokensæ€»æ•°
            "summary_tokens_total": run.get('summary_tokens_total', 0),  # è¢«summaryæ‰çš„tokensæ€»æ•°
            "api_total_tokens_with_trimmed": run['api_total_tokens'] + run.get('trimmed_tokens_total', 0),  # åŒ…å«è¢«trimæ‰çš„tokens
            "api_total_tokens_with_trimmed_and_reset": run['api_total_tokens'] + run.get('trimmed_tokens_total', 0) + run.get('reset_tokens_total', 0),  # åŒ…å«è¢«trimå’Œresetæ‰çš„tokens
            "api_total_tokens_with_all_removed": run['api_total_tokens'] + run.get('trimmed_tokens_total', 0) + run.get('reset_tokens_total', 0) + run.get('thinking_reset_tokens_total', 0) + run.get('summary_tokens_total', 0),  # åŒ…å«æ‰€æœ‰è¢«åˆ æ‰çš„tokens
            "tokens_before_each_assistant": run.get('tokens_before_each_assistant', []),  # æ¯æ¬¡assistantå›å¤å‰çš„ç´¯è®¡tokens
        }
        runs_detail.append(run_info)
    
    save_data["configs"][config_name] = {
        "total_runs": stats['total_runs'],
        "success_runs": stats['success_runs'],
        "error_runs": stats['error_runs'],
        "error_action_runs": stats.get('error_action_runs', 0),  # åŒ…å«error actionçš„runæ•°é‡
        "valid_runs_for_tokens": stats.get('valid_runs_for_tokens', stats['total_runs']),  # ç”¨äºtokenç»Ÿè®¡çš„æœ‰æ•ˆrunæ•°é‡
        "context_length_error_runs": stats['context_length_error_runs'],
        "context_length_error_rate": stats['context_length_error_rate'],
        "improper_ending_runs": stats['improper_ending_runs'],
        "improper_ending_rate": stats['improper_ending_rate'],
        "total_reset_count": stats['total_reset_count'],
        "total_summary_count": stats['total_summary_count'],
        "total_trim_count": stats['total_trim_count'],
        "total_thinking_reset_count": stats['total_thinking_reset_count'],
        "avg_reset_count": stats['avg_reset_count'],
        "avg_summary_count": stats['avg_summary_count'],
        "avg_trim_count": stats['avg_trim_count'],
        "avg_thinking_reset_count": stats['avg_thinking_reset_count'],
        "avg_accuracy": stats['avg_accuracy'],
        "avg_steps": stats['avg_steps'],
        "accuracies": stats['accuracies'],
        "steps": stats['steps'],
        "total_tool_calls": stats['total_tool_calls'],
        "total_tool_content_tokens": stats['total_tool_content_tokens'],
        "total_all_content_tokens": stats['total_all_content_tokens'],
        "total_api_tokens": stats['total_api_tokens'],
        "total_api_prompt_tokens": stats['total_api_prompt_tokens'],
        "total_api_completion_tokens": stats['total_api_completion_tokens'],
        "total_api_cost": stats['total_api_cost'],
        "avg_tool_calls": stats['avg_tool_calls'],
        "avg_tool_content_tokens": stats['avg_tool_content_tokens'],
        "avg_all_content_tokens": stats['avg_all_content_tokens'],
        "avg_api_tokens": stats['avg_api_tokens'],
        "avg_api_prompt_tokens": stats['avg_api_prompt_tokens'],
        "avg_api_completion_tokens": stats['avg_api_completion_tokens'],
        "avg_api_cost": stats['avg_api_cost'],
        "avg_tokens_per_tool_call": stats['avg_tokens_per_tool_call'],
        "total_trimmed_tokens": stats['total_trimmed_tokens'],
        "avg_trimmed_tokens": stats['avg_trimmed_tokens'],
        "total_reset_tokens": stats['total_reset_tokens'],
        "avg_reset_tokens": stats['avg_reset_tokens'],
        "total_thinking_reset_tokens": stats['total_thinking_reset_tokens'],
        "avg_thinking_reset_tokens": stats['avg_thinking_reset_tokens'],
        "total_summary_tokens": stats['total_summary_tokens'],
        "avg_summary_tokens": stats['avg_summary_tokens'],
        "total_api_tokens_with_trimmed": stats['total_api_tokens_with_trimmed'],
        "avg_api_tokens_with_trimmed": stats['avg_api_tokens_with_trimmed'],
        "total_api_tokens_with_trimmed_and_reset": stats['total_api_tokens_with_trimmed_and_reset'],
        "avg_api_tokens_with_trimmed_and_reset": stats['avg_api_tokens_with_trimmed_and_reset'],
        "total_api_tokens_with_all_removed": stats['total_api_tokens_with_all_removed'],
        "avg_api_tokens_with_all_removed": stats['avg_api_tokens_with_all_removed'],
        "runs": runs_detail  # æ·»åŠ æ¯ä¸ªrunçš„è¯¦ç»†æŒ‡æ ‡
    }

# ä¿å­˜åˆ°æ–‡ä»¶
with open(output_path, 'w', encoding='utf-8') as f:
    json.dump(save_data, f, indent=2, ensure_ascii=False)

print(f"\nâœ… åˆ†æç»“æœå·²ä¿å­˜åˆ°: {output_path}")

# ä¿å­˜CSVæ–‡ä»¶
csv_filename = f"analysis_summary_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
csv_path = os.path.join(output_dir, csv_filename)

# æŒ‰configç¼–å·æ’åº
sorted_config_names = sorted(all_configs_stats.keys(), key=lambda x: int(x.split('_')[1]))

# å‡†å¤‡CSVæ•°æ®
csv_data = []
metrics = [
    ('avg_accuracy', 'Average Accuracy'),
    ('avg_steps', 'Average Steps'),
    ('improper_ending_rate', 'Improper Ending Rate'),
    ('improper_ending_runs', 'Improper Ending Count'),
    ('context_length_error_rate', 'Context Length Error Rate'),
    ('context_length_error_runs', 'Context Length Error Count'),
    ('total_reset_count', 'Total Reset Count'),
    ('avg_reset_count', 'Average Reset Count'),
    ('total_summary_count', 'Total Summary Count'),
    ('avg_summary_count', 'Average Summary Count'),
    ('total_trim_count', 'Total Trim Count'),
    ('avg_trim_count', 'Average Trim Count'),
    ('total_thinking_reset_count', 'Total Thinking Reset Count'),
    ('avg_thinking_reset_count', 'Average Thinking Reset Count'),
    ('avg_tool_calls', 'Average Tool Calls'),
    ('total_tool_content_tokens', 'Total Tool Content Tokens'),
    ('avg_tool_content_tokens', 'Average Tool Content Tokens'),
    ('total_all_content_tokens', 'Total All Content Tokens'),
    ('avg_all_content_tokens', 'Average All Content Tokens'),
    ('total_api_tokens', 'Total API Tokens'),
    ('avg_api_tokens', 'Average API Tokens'),
    ('total_api_cost', 'Total API Cost ($)'),
    ('avg_api_cost', 'Average API Cost ($)'),
    ('total_trimmed_tokens', 'Total Trimmed Tokens'),
    ('avg_trimmed_tokens', 'Average Trimmed Tokens'),
    ('total_reset_tokens', 'Total Reset Tokens'),
    ('avg_reset_tokens', 'Average Reset Tokens'),
    ('total_thinking_reset_tokens', 'Total Thinking Reset Tokens'),
    ('avg_thinking_reset_tokens', 'Average Thinking Reset Tokens'),
    ('total_summary_tokens', 'Total Summary Tokens'),
    ('avg_summary_tokens', 'Average Summary Tokens'),
    ('total_api_tokens_with_trimmed', 'Total API Tokens (incl. Trimmed)'),
    ('avg_api_tokens_with_trimmed', 'Average API Tokens (incl. Trimmed)'),
    ('total_api_tokens_with_trimmed_and_reset', 'Total API Tokens (incl. Trimmed+Reset)'),
    ('avg_api_tokens_with_trimmed_and_reset', 'Average API Tokens (incl. Trimmed+Reset)'),
    ('total_api_tokens_with_all_removed', 'Total API Tokens (incl. All Removed)'),
    ('avg_api_tokens_with_all_removed', 'Average API Tokens (incl. All Removed)')
]

# å†™å…¥CSV
with open(csv_path, 'w', newline='', encoding='utf-8') as f:
    writer = csv.writer(f)
    
    # å¦‚æœæœ‰åˆ†ç»„ä¿¡æ¯ï¼Œå†™å…¥åˆ†ç»„è¯´æ˜
    if group_by_seed and config_groups:
        writer.writerow(['# Grouping Mode: Enabled'])
        writer.writerow(['# Config Groups:'])
        for group_id, member_configs in sorted(config_groups.items()):
            config_names = [f"config_{c}" for c in member_configs]
            writer.writerow([f"# Group {group_id}:", ', '.join(config_names)])
        writer.writerow([])  # ç©ºè¡Œåˆ†éš”
    else:
        writer.writerow(['# Grouping Mode: Disabled'])
        writer.writerow([])  # ç©ºè¡Œåˆ†éš”
    
    # å†™å…¥è¡¨å¤´
    header = ['Metric'] + sorted_config_names
    writer.writerow(header)
    
    # å†™å…¥æ¯ä¸ªæŒ‡æ ‡çš„è¡Œ
    for metric_key, metric_name in metrics:
        row = [metric_name]
        for config_name in sorted_config_names:
            value = all_configs_stats[config_name][metric_key]
            # æ ¹æ®æŒ‡æ ‡ç±»å‹æ ¼å¼åŒ–æ•°å€¼
            if metric_key == 'avg_accuracy':
                row.append(f"{value:.4f}")
            elif metric_key == 'avg_steps':
                row.append(f"{value:.2f}")
            elif metric_key == 'improper_ending_rate':
                row.append(f"{value:.4f}")
            elif metric_key == 'improper_ending_runs':
                row.append(f"{int(value)}")
            elif metric_key == 'context_length_error_rate':
                row.append(f"{value:.4f}")
            elif metric_key == 'context_length_error_runs':
                row.append(f"{int(value)}")
            elif metric_key in ['total_reset_count', 'total_summary_count', 'total_trim_count', 'total_thinking_reset_count']:
                row.append(f"{int(value)}")
            elif metric_key in ['avg_reset_count', 'avg_summary_count', 'avg_trim_count', 'avg_thinking_reset_count']:
                row.append(f"{value:.2f}")
            elif metric_key in ['total_tool_content_tokens', 'total_all_content_tokens', 'total_api_tokens', 'total_trimmed_tokens', 'total_reset_tokens', 'total_thinking_reset_tokens', 'total_summary_tokens', 'total_api_tokens_with_trimmed', 'total_api_tokens_with_trimmed_and_reset', 'total_api_tokens_with_all_removed']:
                row.append(f"{int(value)}")  # æ€»tokensæ•°æ˜¾ç¤ºä¸ºæ•´æ•°
            elif metric_key in ['avg_tool_content_tokens', 'avg_all_content_tokens', 'avg_api_tokens', 'avg_trimmed_tokens', 'avg_reset_tokens', 'avg_thinking_reset_tokens', 'avg_summary_tokens', 'avg_api_tokens_with_trimmed', 'avg_api_tokens_with_trimmed_and_reset', 'avg_api_tokens_with_all_removed']:
                row.append(f"{value:.2f}")  # å¹³å‡tokensä¿ç•™2ä½å°æ•°
            elif metric_key in ['avg_api_cost', 'total_api_cost']:
                row.append(f"{value:.8f}")  # costä¿ç•™æ›´å¤šå°æ•°ä½
            else:
                row.append(f"{value:.2f}")
        writer.writerow(row)

print(f"âœ… CSVæ±‡æ€»æ–‡ä»¶å·²ä¿å­˜åˆ°: {csv_path}")

# ä¿å­˜tokenså˜åŒ–è¶‹åŠ¿CSVæ–‡ä»¶
tokens_progression_filename = f"tokens_progression_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
tokens_progression_path = os.path.join(output_dir, tokens_progression_filename)

with open(tokens_progression_path, 'w', newline='', encoding='utf-8') as f:
    writer = csv.writer(f)
    
    # å†™å…¥è¡¨å¤´
    writer.writerow(['# Tokens Progression Before Each Assistant Response'])
    writer.writerow(['# This file shows the cumulative token count before each assistant message in each run'])
    writer.writerow([])
    
    # ä¸ºæ¯ä¸ªconfigå†™å…¥æ•°æ®
    for config_name in sorted_config_names:
        stats = all_configs_stats[config_name]
        
        writer.writerow([f'### {config_name} ###'])
        writer.writerow(['Run Index', 'Assistant Index', 'Cumulative Tokens Before Assistant'])
        
        # éå†æ¯ä¸ªrun
        for run_idx, run in enumerate(stats['runs']):
            tokens_progression = run.get('tokens_before_each_assistant', [])
            
            if tokens_progression:
                for item in tokens_progression:
                    assistant_idx = item['assistant_index']
                    cumulative_tokens = item['cumulative_tokens']
                    writer.writerow([run_idx, assistant_idx, cumulative_tokens])
            else:
                # å¦‚æœæ²¡æœ‰æ•°æ®ï¼Œå†™å…¥ä¸€è¡Œè¯´æ˜
                writer.writerow([run_idx, 'N/A', 'No data'])
        
        writer.writerow([])  # ç©ºè¡Œåˆ†éš”ä¸åŒçš„config

print(f"âœ… Tokenså˜åŒ–è¶‹åŠ¿æ–‡ä»¶å·²ä¿å­˜åˆ°: {tokens_progression_path}")
print("=" * 100)

