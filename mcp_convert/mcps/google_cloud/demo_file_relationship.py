#!/usr/bin/env python3
"""
æ¼”ç¤º JSON æ–‡ä»¶å’Œ SQLite æ•°æ®åº“ä¹‹é—´çš„å…³è”å…³ç³»
"""

import sys
import os
import json
import sqlite3

sys.path.insert(0, os.path.dirname(__file__))

from database_utils import GoogleCloudDatabase


def print_section(title):
    print(f"\n{'=' * 70}")
    print(f"  {title}")
    print('=' * 70)


def main():
    print_section("JSON æ–‡ä»¶å’Œ SQLite æ•°æ®åº“å…³è”æ¼”ç¤º")
    
    db = GoogleCloudDatabase()
    
    # ==================== æ­¥éª¤ 1: æŸ¥çœ‹ JSON å…ƒæ•°æ® ====================
    print_section("æ­¥éª¤ 1: æŸ¥çœ‹ JSON å…ƒæ•°æ®")
    
    # è¯»å–è¡¨å…ƒæ•°æ®
    tables_file = os.path.join(db.data_dir, "bigquery_tables.json")
    with open(tables_file, 'r') as f:
        tables = json.load(f)
    
    # é€‰æ‹©ä¸€ä¸ªè¡¨æ¥æ¼”ç¤º
    table_key = "project-1:sales_dataset.transactions"
    if table_key in tables:
        table_info = tables[table_key]
        print(f"\nğŸ“‹ JSON å…ƒæ•°æ®ï¼ˆ{table_key}ï¼‰:")
        print(f"  - è¡¨ ID: {table_info['tableId']}")
        print(f"  - é¡¹ç›® ID: {table_info['projectId']}")
        print(f"  - æ•°æ®é›† ID: {table_info['datasetId']}")
        print(f"  - è®°å½•çš„è¡Œæ•°: {table_info['numRows']}")
        print(f"  - æœ€åä¿®æ”¹: {table_info['modified']}")
        print(f"\n  Schema (å‰ 3 åˆ—):")
        for field in table_info['schema'][:3]:
            print(f"    - {field['name']}: {field['type']} ({field['mode']})")
    
    # ==================== æ­¥éª¤ 2: æŸ¥çœ‹ SQLite å®é™…æ•°æ® ====================
    print_section("æ­¥éª¤ 2: æŸ¥çœ‹ SQLite å®é™…æ•°æ®")
    
    # è¿æ¥åˆ° SQLite æ•°æ®åº“
    sqlite_db = os.path.join(db.data_dir, "bigquery_data.db")
    conn = sqlite3.connect(sqlite_db)
    cursor = conn.cursor()
    
    # æŸ¥çœ‹è¡¨ç»“æ„
    table_name = "project-1_sales_dataset_transactions"
    print(f"\nğŸ—„ï¸  SQLite è¡¨ç»“æ„ï¼ˆ{table_name}ï¼‰:")
    cursor.execute(f'PRAGMA table_info("{table_name}")')
    columns = cursor.fetchall()
    for col in columns:
        print(f"  - {col[1]}: {col[2]} {'NOT NULL' if col[3] else ''}")
    
    # æŸ¥çœ‹å®é™…è¡Œæ•°
    cursor.execute(f'SELECT COUNT(*) FROM "{table_name}"')
    actual_row_count = cursor.fetchone()[0]
    print(f"\nğŸ“Š SQLite å®é™…è¡Œæ•°: {actual_row_count}")
    
    # æŸ¥çœ‹å‡ è¡Œæ•°æ®
    print(f"\nğŸ“ SQLite æ•°æ®ç¤ºä¾‹ï¼ˆå‰ 3 è¡Œï¼‰:")
    cursor.execute(f'SELECT * FROM "{table_name}" LIMIT 3')
    rows = cursor.fetchall()
    for i, row in enumerate(rows, 1):
        print(f"  Row {i}: transaction_id={row[0]}, amount={row[2]}")
    
    conn.close()
    
    # ==================== æ­¥éª¤ 3: æ¼”ç¤ºå…³è” - æ’å…¥æ•°æ® ====================
    print_section("æ­¥éª¤ 3: æ¼”ç¤ºå…³è” - æ’å…¥æ•°æ®")
    
    print("\nğŸ”„ æ’å…¥æ–°æ•°æ®...")
    new_row = [{
        "transaction_id": "txn_demo_relation",
        "customer_id": "cust_demo",
        "amount": 999.99,
        "currency": "USD",
        "timestamp": "2024-02-01T15:00:00Z"
    }]
    
    # è®°å½•æ’å…¥å‰çš„çŠ¶æ€
    print(f"\næ’å…¥å‰:")
    print(f"  - JSON å…ƒæ•°æ®æ˜¾ç¤ºè¡Œæ•°: {table_info['numRows']}")
    
    # æ’å…¥æ•°æ®
    success = db.insert_table_rows("project-1", "sales_dataset", "transactions", new_row)
    print(f"  - æ’å…¥æ“ä½œ: {'âœ… æˆåŠŸ' if success else 'âŒ å¤±è´¥'}")
    
    # æ£€æŸ¥æ’å…¥åçš„çŠ¶æ€
    print(f"\næ’å…¥å:")
    
    # 1. JSON å…ƒæ•°æ®è‡ªåŠ¨æ›´æ–°äº†
    with open(tables_file, 'r') as f:
        tables_updated = json.load(f)
    table_info_updated = tables_updated[table_key]
    print(f"  - JSON å…ƒæ•°æ®æ›´æ–°åè¡Œæ•°: {table_info_updated['numRows']}")
    print(f"  - JSON ä¿®æ”¹æ—¶é—´æ›´æ–°: {table_info_updated['modified']}")
    
    # 2. SQLite æ•°æ®ä¹Ÿå¢åŠ äº†
    conn = sqlite3.connect(sqlite_db)
    cursor = conn.cursor()
    cursor.execute(f'SELECT COUNT(*) FROM "{table_name}"')
    new_row_count = cursor.fetchone()[0]
    print(f"  - SQLite å®é™…è¡Œæ•°: {new_row_count}")
    
    # éªŒè¯æ–°æ•°æ®ç¡®å®å­˜åœ¨
    cursor.execute(f'SELECT * FROM "{table_name}" WHERE transaction_id = "txn_demo_relation"')
    new_data = cursor.fetchone()
    if new_data:
        print(f"  - âœ… åœ¨ SQLite ä¸­æ‰¾åˆ°æ–°æ•°æ®: {new_data[0]}, amount={new_data[2]}")
    
    conn.close()
    
    # ==================== æ­¥éª¤ 4: æ¼”ç¤ºå…³è” - æŸ¥è¯¢ç¼“å­˜ ====================
    print_section("æ­¥éª¤ 4: æ¼”ç¤ºå…³è” - æŸ¥è¯¢ç¼“å­˜")
    
    # æ‰§è¡ŒæŸ¥è¯¢
    query = f'SELECT * FROM `project-1.sales_dataset.transactions` WHERE transaction_id = "txn_demo_relation"'
    print(f"\nğŸ” æ‰§è¡ŒæŸ¥è¯¢: {query}")
    
    result = db.run_bigquery_query(query)
    print(f"  - æŸ¥è¯¢çŠ¶æ€: {result['status']}")
    print(f"  - è¿”å›è¡Œæ•°: {result['totalRows']}")
    print(f"  - æ˜¯å¦ç¼“å­˜: {result.get('cached', False)}")
    
    # æŸ¥çœ‹ç¼“å­˜æ–‡ä»¶
    cache_file = os.path.join(db.data_dir, "query_results.json")
    with open(cache_file, 'r') as f:
        cache = json.load(f)
    print(f"\nğŸ’¾ æŸ¥è¯¢ç»“æœå·²ç¼“å­˜åˆ° query_results.json")
    print(f"  - ç¼“å­˜çš„æŸ¥è¯¢æ•°: {len(cache)}")
    
    # å†æ¬¡æ‰§è¡Œç›¸åŒæŸ¥è¯¢
    print(f"\nğŸ” å†æ¬¡æ‰§è¡Œç›¸åŒæŸ¥è¯¢...")
    result2 = db.run_bigquery_query(query)
    print(f"  - æ˜¯å¦ä½¿ç”¨ç¼“å­˜: {result2.get('cached', False)}")
    
    # ==================== æ­¥éª¤ 5: æ¼”ç¤ºå…³è” - åˆ é™¤æ•°æ® ====================
    print_section("æ­¥éª¤ 5: æ¼”ç¤ºå…³è” - åˆ é™¤æ•°æ®")
    
    print(f"\nğŸ—‘ï¸  åˆ é™¤æµ‹è¯•æ•°æ®...")
    deleted = db.delete_table_rows("project-1", "sales_dataset", "transactions",
                                   "transaction_id = 'txn_demo_relation'")
    print(f"  - åˆ é™¤äº† {deleted} è¡Œ")
    
    # æ£€æŸ¥åˆ é™¤åçš„çŠ¶æ€
    print(f"\nåˆ é™¤å:")
    
    # 1. JSON å…ƒæ•°æ®åˆæ›´æ–°äº†
    with open(tables_file, 'r') as f:
        tables_final = json.load(f)
    table_info_final = tables_final[table_key]
    print(f"  - JSON å…ƒæ•°æ®è¡Œæ•°æ¢å¤: {table_info_final['numRows']}")
    
    # 2. SQLite æ•°æ®è¢«åˆ é™¤
    conn = sqlite3.connect(sqlite_db)
    cursor = conn.cursor()
    cursor.execute(f'SELECT COUNT(*) FROM "{table_name}"')
    final_row_count = cursor.fetchone()[0]
    print(f"  - SQLite è¡Œæ•°æ¢å¤: {final_row_count}")
    
    # 3. ç¼“å­˜è¢«æ¸…é™¤
    with open(cache_file, 'r') as f:
        cache_final = json.load(f)
    print(f"  - æŸ¥è¯¢ç¼“å­˜è¢«æ¸…é™¤: {len(cache_final)} ä¸ªç¼“å­˜")
    
    conn.close()
    
    # ==================== æ€»ç»“ ====================
    print_section("æ€»ç»“ï¼šJSON å’Œ SQLite çš„å…³è”")
    
    print("""
âœ… å…³è”å…³ç³»æ€»ç»“:

1. **Schema å®šä¹‰ï¼ˆJSON â†’ SQLiteï¼‰**
   - JSON æ–‡ä»¶å®šä¹‰è¡¨çš„ schemaï¼ˆåˆ—åã€ç±»å‹ï¼‰
   - SQLite æ ¹æ® schema åˆ›å»ºè¡¨ç»“æ„
   - å…³ç³»ï¼šJSON æ˜¯"è®¾è®¡å›¾"ï¼ŒSQLite æ˜¯"å»ºç­‘"

2. **æ•°æ®å­˜å‚¨ï¼ˆSQLite + JSONï¼‰**
   - SQLite å­˜å‚¨å®é™…çš„è¡Œæ•°æ®
   - JSON è®°å½•ç»Ÿè®¡ä¿¡æ¯ï¼ˆè¡Œæ•°ã€å¤§å°ã€ä¿®æ”¹æ—¶é—´ï¼‰
   - å…³ç³»ï¼šSQLite æ˜¯"ä»“åº“"ï¼ŒJSON æ˜¯"æ¸…å•"

3. **æ•°æ®æ“ä½œï¼ˆåŒå‘åŒæ­¥ï¼‰**
   - INSERT/UPDATE/DELETE æ“ä½œ SQLite
   - è‡ªåŠ¨æ›´æ–° JSON å…ƒæ•°æ®
   - å…³ç³»ï¼šæ“ä½œåè‡ªåŠ¨åŒæ­¥ï¼Œä¿æŒä¸€è‡´

4. **æŸ¥è¯¢ç¼“å­˜ï¼ˆJSONï¼‰**
   - æŸ¥è¯¢ç»“æœç¼“å­˜åœ¨ JSON æ–‡ä»¶
   - æ•°æ®ä¿®æ”¹æ—¶æ¸…é™¤ç¼“å­˜
   - å…³ç³»ï¼šç¼“å­˜æé«˜æ€§èƒ½ï¼Œä¿®æ”¹æ—¶å¤±æ•ˆ

5. **æ–‡ä»¶åˆ†å·¥**
   ```
   bigquery_datasets.json    â†’ æ•°æ®é›†é…ç½®
   bigquery_tables.json      â†’ è¡¨ schema + ç»Ÿè®¡
   bigquery_data.db          â†’ è¡¨çš„å®é™…æ•°æ®
   query_results.json        â†’ æŸ¥è¯¢ç»“æœç¼“å­˜
   storage_*.json            â†’ Cloud Storage å…ƒæ•°æ®
   compute_*.json            â†’ Compute Engine å…ƒæ•°æ®
   iam_*.json                â†’ IAM å…ƒæ•°æ®
   ```

ğŸ¯ æ ¸å¿ƒè®¾è®¡ç†å¿µï¼š
  - JSON â†’ å…ƒæ•°æ®ã€é…ç½®ã€ç¼“å­˜ï¼ˆäººç±»å¯è¯»ï¼‰
  - SQLite â†’ æ•°æ®ã€æŸ¥è¯¢ï¼ˆæœºå™¨ä¼˜åŒ–ï¼‰
  - è‡ªåŠ¨åŒæ­¥ â†’ ä¿æŒä¸€è‡´æ€§
    """)
    
    print("\n" + "=" * 70)
    print("æ¼”ç¤ºå®Œæˆï¼")
    print("=" * 70)


if __name__ == "__main__":
    main()

